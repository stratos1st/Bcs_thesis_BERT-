{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Greek_bert_replace_numbers.ipynb","provenance":[],"collapsed_sections":["4uHTL519iZVZ","nUbFqZMTYFOy","CL6zGRvng0cb","t5SEw2hUfv5G","gMPeoqpOf7p3","oujVuInLieHc","_Ig-lwAAkh0w","f1h5wBjHw_Gs"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"13e5fc4be2cc419eba3b9e30e94e55d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2d0b04795a3c48bcad1d44a1cbe897b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3d848589526243089ebf867578bbcea4","IPY_MODEL_daf53fb5efa547fab17532a19eda651b"]}},"2d0b04795a3c48bcad1d44a1cbe897b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d848589526243089ebf867578bbcea4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90c7eaf603484860b39f65297aa88131","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":459,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":459,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6115bd7340344d2a5c790f042c59430"}},"daf53fb5efa547fab17532a19eda651b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a352744b2cdb40458da8e4f003eb0950","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 459/459 [00:00&lt;00:00, 4.93kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43be67e825bb4040a9990a5745d665b1"}},"90c7eaf603484860b39f65297aa88131":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e6115bd7340344d2a5c790f042c59430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a352744b2cdb40458da8e4f003eb0950":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"43be67e825bb4040a9990a5745d665b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca00a8b3d73649b2a5c07c75d895b73e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4fe3bbab12b74bd6a9c6e38ee1ad7714","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_77a1998081604df0a47cc9190da4e525","IPY_MODEL_d95d0dbd2e1448da9d317b244ccde3af"]}},"4fe3bbab12b74bd6a9c6e38ee1ad7714":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77a1998081604df0a47cc9190da4e525":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_413035633579458fb69db5d0d2753353","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":454248854,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":454248854,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffacd5ee23c6479da5cd0919b9c59e91"}},"d95d0dbd2e1448da9d317b244ccde3af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8ede6e09ef4a45d3b5f86a9eb4a7025a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 454M/454M [00:08&lt;00:00, 53.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8cd621507b78480a8cc8e4efc500b95c"}},"413035633579458fb69db5d0d2753353":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ffacd5ee23c6479da5cd0919b9c59e91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ede6e09ef4a45d3b5f86a9eb4a7025a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8cd621507b78480a8cc8e4efc500b95c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8402d6e11a3499ebb9a9af0193dccf8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4925dbcee08a475094c49fa1eb2616e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_05ec6082141f457e92be61cb6d52324f","IPY_MODEL_49b75b3ece7c473eacebf130014538b0"]}},"4925dbcee08a475094c49fa1eb2616e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05ec6082141f457e92be61cb6d52324f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4dfd79aa43a2472d8cfec24e1e97cecd","_dom_classes":[],"description":"split=test: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1189,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1189,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49ed70026c3a41e99cdfa012e0b88101"}},"49b75b3ece7c473eacebf130014538b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b73d0d6041b54ea093cb276883c49e5c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1189/1189 [10:18&lt;00:00,  2.03it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e70437118dc41fca011d2706c9298c1"}},"4dfd79aa43a2472d8cfec24e1e97cecd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"49ed70026c3a41e99cdfa012e0b88101":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b73d0d6041b54ea093cb276883c49e5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e70437118dc41fca011d2706c9298c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbd96e8c6b0549e38233182b9f96743b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d6d2fe660109445eb8edfd8e3ca2582c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6077214e544b4cc28c7eb48a75524398","IPY_MODEL_a7092c11a89b449980b3046f241f6396"]}},"d6d2fe660109445eb8edfd8e3ca2582c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6077214e544b4cc28c7eb48a75524398":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_52b6a5e403d748f3920ee554d1bbbc9f","_dom_classes":[],"description":"predictions to cpu: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":9512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3fc849dee0e64f80a26e9611e0a3b482"}},"a7092c11a89b449980b3046f241f6396":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d334e2f4283141adb3ef6c16048f3f05","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9512/9512 [01:40&lt;00:00, 94.85it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc396d4159cf4f4a9b6d100e3390eb51"}},"52b6a5e403d748f3920ee554d1bbbc9f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3fc849dee0e64f80a26e9611e0a3b482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d334e2f4283141adb3ef6c16048f3f05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc396d4159cf4f4a9b6d100e3390eb51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"EEDBycDQOHOY"},"source":["from argparse import Namespace\n","args = Namespace(\n","  # Data and path information\n","  dataset_path=\"/content/drive/MyDrive/thesis/dataset/\",\n","  model_state_file=\"model_subject_numbers_replace.pth\",\n","  save_dir=\"/content/drive/MyDrive/thesis/models/greek_BERT_replace_numbers/\", # save models here\n","  no_classes = 2285, # subject 2285, chapter 389, volume 47\n","  class_name = 'subject',\n","  # Training hyper parameters\n","  seed=1335,\n","  num_epochs=15,\n","  early_stopping_criteria=2,\n","  learning_rate=0.00002,\n","  batch_size=8,\n","  # Runtime options\n","  cuda=True,\n","  reload_from_files=False, # to continue training from checkpoint or evaluate a model\n","  reload_name=\"model_volume_numbers_replace.pth\",\n","  expand_filepaths_to_save_dir=True,\n","  run_training=False #if false it will run only on the test set\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uHTL519iZVZ"},"source":["###tmp"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N1VlTthMldd","executionInfo":{"status":"ok","timestamp":1620467805974,"user_tz":-180,"elapsed":38397,"user":{"displayName":"Art-LesvosVillas Greece","photoUrl":"","userId":"06832438583615092524"}},"outputId":"53de7462-6bf3-4842-cb27-c7832614f2f3"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rqkz0Hg1O2Up","executionInfo":{"status":"ok","timestamp":1620467819720,"user_tz":-180,"elapsed":52129,"user":{"displayName":"Art-LesvosVillas Greece","photoUrl":"","userId":"06832438583615092524"}},"outputId":"fb64cad3-6ec5-43ad-d4b6-45ddb8003fac"},"source":["# from collections import Counter\n","import re\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","from tqdm import trange\n","\n","!pip install torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","print('Loading torchmetrics lib...')\n","# https://torchmetrics.readthedocs.io/en/latest/index.html\n","# !pip install torchmetrics\n","# from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1\n","from sklearn.metrics import f1_score, recall_score, precision_score\n","\n","# reading json files\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","\n","# huggingface lib bert\n","print('Loading transformers lib...')\n","!pip install transformers\n","from transformers import AutoTokenizer, AutoModel, BertTokenizer"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Loading torchmetrics lib...\n","Loading transformers lib...\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 15.5MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 54.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 32.1MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VlFvFQUvOAcZ","executionInfo":{"status":"ok","timestamp":1620467819722,"user_tz":-180,"elapsed":52124,"user":{"displayName":"Art-LesvosVillas Greece","photoUrl":"","userId":"06832438583615092524"}},"outputId":"f2f7b74e-871f-4ea7-be7c-96e7b059dbf4"},"source":["# Check CUDA and gpu available\n","if not torch.cuda.is_available():\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Using CUDA: {}\".format(args.cuda))\n","if args.cuda:\n","  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using CUDA: True\n","GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nUbFqZMTYFOy"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"x5SVi3W8YFUb"},"source":["# sets the seed everywhere for reprodusable results\n","def set_seed_everywhere(seed, cuda):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  # random.seed(seed)\n","  # !!!! may need to add hugingface init seed\n","  if cuda:\n","    torch.cuda.manual_seed_all(seed)\n","\n","# creates non existing directories\n","def handle_dirs(dirpath):\n","  if not os.path.exists(dirpath):\n","    os.makedirs(dirpath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A89dNcfGViGB"},"source":["### The Vectorizer"]},{"cell_type":"code","metadata":{"id":"8jG3SJWzViOn"},"source":["class LegalVectorizer(object):\n","  \"\"\" The Vectorizer\"\"\"\n","  def __init__(self):\n","    print('Loading BERT tokenizer...')\n","    self.tokenizer = BertTokenizer(\"/content/drive/MyDrive/thesis/Greek_Bert_vocab_number.txt\",\n","                           model_max_length=512, use_fast=True)\n","  def vectorize(self, text):\n","    \"\"\"\n","    Args:\n","        text (list of str):\n","    Returns:\n","        dictionary: \"vector\" is a tensor with a list of encoded text paded to max_len, ready for import to BERT\n","                    \"mask\" is a tensor with a list of masks ready for import to BERT\n","    \"\"\"\n","    encoded_dict = self.tokenizer(\n","                    text,                      \n","                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                    padding = True, # pad to longest in batch\n","                    truncation = True, # truncates sentenses to 512, max bert length\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',     # Return pytorch tensors.\n","                )\n","    return {\"vector\" : encoded_dict['input_ids'],\n","            \"mask\" : encoded_dict['attention_mask']}\n","\n","  def get_pad_tocken(self):\n","    return self.tokenizer.pad_token_id\n","\n","  def to_words(self, vector, remove_pads=True):\n","    \"\"\"\n","    Args:\n","        vector (tensor): list of vectors to decode\n","        remove_pads : remove pad \n","    Returns:\n","        list of lists of words coresponding to the vector values\n","    \"\"\"\n","    if remove_pads:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v[v.nonzero()]) for v in vector]\n","    else:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v) for v in vector]\n","    return ans\n","      "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CL6zGRvng0cb"},"source":["###The dataset"]},{"cell_type":"code","metadata":{"id":"9OVA8YQTg0QD"},"source":["class LegalDataset(Dataset):\n","  def __init__(self):\n","    print(\"loading validation set...\")\n","    self.val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","    self.validation_size = len(self.val_df)\n","    print(\"loading training set...\")\n","    self.train_df = pd.read_pickle(args.dataset_path + \"train.pkl\")\n","    self.train_size = len(self.train_df)\n","    print(\"loading test set...\")\n","    self.test_df = pd.read_pickle(args.dataset_path + \"test.pkl\")\n","    self.test_size = len(self.test_df)\n","    # check the dataset size (dataset has extra files when uploaded to google drive. it mekes copies ex. \"123 (1).json\")\n","    if self.val_df.shape[0]!=9511 or self.train_df.shape[0]!=28536 or self.test_df.shape[0]!=9516:\n","      print(self.val_df.shape[0])\n","      print(self.train_df.shape[0])\n","      print(self.test_df.shape[0])\n","      print(\"!! ERROR dataset size !!\")\n","      exit()\n","\n","    print(\"Processing dataset...\")\n","    # replace class names with 0...n numbers\n","    class_namess = pd.concat([ self.val_df[args.class_name],\n","                             self.train_df[args.class_name],\n","                             self.test_df[args.class_name] ]).unique()\n","    self.class_names = dict(zip(class_namess, range(len(class_namess))))\n","    self.val_df[args.class_name] = self.val_df[args.class_name].replace(self.class_names)\n","    self.train_df[args.class_name] = self.train_df[args.class_name].replace(self.class_names)\n","    self.test_df[args.class_name] = self.test_df[args.class_name].replace(self.class_names)\n","    # delete usless stuff\n","    self.val_df = self.val_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.train_df = self.train_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.test_df = self.test_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","\n","    text = []\n","    for _, row in self.val_df.iterrows():\n","      tmp = row['header'] + ' ' + row['articles']\n","      text.append(re.sub(r\"\\d+\", \"#\", tmp))\n","    self.val_df['header'] = text\n","\n","    text = []\n","    for _, row in self.train_df.iterrows():\n","      tmp = row['header'] + ' ' + row['articles']\n","      text.append(re.sub(r\"\\d+\", \"#\", tmp))\n","    self.train_df['header'] = text\n","\n","    text = []\n","    for _, row in self.test_df.iterrows():\n","      tmp = row['header'] + ' ' + row['articles']\n","      text.append(re.sub(r\"\\d+\", \"#\", tmp))\n","    self.test_df['header'] = text\n","\n","    self._vectorizer = LegalVectorizer()\n","    self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                          'val': (self.val_df, self.validation_size),\n","                          'test': (self.test_df, self.test_size)}\n","\n","    self.set_split('train')\n","\n","    print(\"Calculating frequences...\")\n","    self.class_counts = []\n","    for v in range(args.no_classes):\n","      tmp = self.train_df[self.train_df[args.class_name]==v][args.class_name].count()\n","      if tmp>0:\n","        self.class_counts.append(tmp)\n","      else:\n","        self.class_counts.append(0)\n","    # self.class_weights = 10000.0 / torch.tensor(self.class_counts, dtype=torch.float32) \n","\n","  def get_vectorizer(self):\n","    \"\"\" returns the vectorizer \"\"\"\n","    return self._vectorizer\n","\n","  def set_split(self, split):\n","    \"\"\" selects the splits in the dataset using _lookup_dict \"\"\"\n","    # self._target_split = split\n","    self._target_df, self._target_size = self._lookup_dict[split]\n","\n","  def __len__(self):\n","    return self._target_size\n","\n","  def __getitem__(self, index):\n","    \"\"\"the primary entry point method for PyTorch datasets\n","    Args:\n","        index (int): the index to the data point \n","    Returns:\n","        a dictionary holding the data point's. text is NOT vectorized yet.\n","    \"\"\"\n","    row = self._target_df.iloc[index]\n","    target = row[args.class_name]\n","    text = row['header']\n","\n","    return {'target': target,\n","            'text' : text}\n","      \n","  def get_num_batches(self, batch_size):\n","    \"\"\"Given a batch size, return the number of batches in the dataset\n","    Args:\n","      batch_size (int)\n","    Returns:\n","      number of batches in the dataset\n","    \"\"\"\n","    return len(self) // batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5SEw2hUfv5G"},"source":["###Dataloader"]},{"cell_type":"code","metadata":{"id":"-q4zXTEffv_V"},"source":["# this is a cool way to save some time in training. Havent done it yet, may effect accuracy\n","# http://mccormickml.com/2020/07/29/smart-batching-tutorial\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"): \n","  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                          shuffle=shuffle, drop_last=drop_last)\n","\n","  for data_dict in dataloader:\n","    #vectorize batch text\n","    tmp = dataset.get_vectorizer().vectorize(data_dict['text'])\n","    mask, vector = tmp['mask'], tmp['vector']\n","    data_dict['vector'] = vector\n","    data_dict['mask'] = mask\n","    del data_dict['text']\n","\n","    out_data_dict = {}\n","    for name, tensor in data_dict.items():\n","        out_data_dict[name] = data_dict[name].to(device)\n","    yield out_data_dict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMPeoqpOf7p3"},"source":["###The Model"]},{"cell_type":"code","metadata":{"id":"3GJCeb23f7wa"},"source":["class LegalClassifier(nn.Module):\n","  \"\"\" greek-Bert model with an extra linear layer, which takes \n","      the cls tocken as input, for classification \"\"\"\n","  def __init__(self, no_classes):\n","    \"\"\"\n","    Args:\n","        no_classes (int): the size of the linear layer\n","    \"\"\"\n","    super(LegalClassifier, self).__init__()\n","    print(\"Loading greek-Bert...\")\n","    self.bert = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","    self.dropout = nn.Dropout(0.1)\n","    self.fc = nn.Linear(768,no_classes)\n","    # for param in self.bert.parameters():\n","    #   param.requires_grad = False\n","\n","  def forward(self, input, mask, apply_softmax=False):\n","    \"\"\"The forward pass of the classifier\n","    Args:\n","        input (torch.Tensor): an input data tensor.\n","        mask (torch.Tensor): the coresponding masks for BERT\n","        apply_softmax (bool): whether or not to apply soflmax to the output layer\n","    Returns:\n","        the resulting tensor. tensor.shape should be (batch, output_dim)\n","    \"\"\"\n","    output = self.bert(input_ids=input, attention_mask=mask, \n","                       output_attentions=False, output_hidden_states=False)\n","    x = output.pooler_output # coresponds to CLS token\n","    x = self.dropout(x) \n","    x = self.fc(x)\n","    if apply_softmax:\n","        x = F.softmax(x, dim=1)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oujVuInLieHc"},"source":["###helper functions"]},{"cell_type":"code","metadata":{"id":"wEbV1KG-ieOs"},"source":["def make_train_state(args):\n","  return {'stop_early': False,\n","          'early_stopping_step': 0,\n","          'early_stopping_best_val': 1e8,\n","          'learning_rate': args.learning_rate,\n","          'epoch_index': 0,\n","          'train_loss': [],\n","          'train_acc': [],\n","          'val_loss': [],\n","          'val_acc': [],\n","          'test_loss': -1,\n","          'test_acc': -1,\n","          'model_filename': args.model_state_file}\n","\n","def update_train_state(args, model, train_state):\n","  \"\"\"Handle the training state updates.\n","\n","  Components:\n","    - Early Stopping: Prevent overfitting.\n","    - Model Checkpoint: Model is saved if the model is better\n","\n","  :param args: main arguments\n","  :param model: model to train\n","  :param train_state: a dictionary representing the training state values\n","  :returns:\n","      a new train_state\n","  \"\"\"\n","  # Save one model at least\n","  if train_state['epoch_index'] == 0:\n","    torch.save(model.state_dict(), train_state['model_filename'])\n","    train_state['stop_early'] = False\n","\n","  # Save model if performance improved\n","  elif train_state['epoch_index'] >= 1:\n","    loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","    # If loss worsened\n","    if loss_t >= train_state['early_stopping_best_val']:\n","      # Update step\n","      train_state['early_stopping_step'] += 1\n","    # Loss decreased\n","    else:\n","      # Save the best model\n","      if loss_t < train_state['early_stopping_best_val']:\n","          torch.save(model.state_dict(), train_state['model_filename'])\n","      # Reset early stopping step\n","      train_state['early_stopping_step'] = 0\n","\n","    # Stop early ?\n","    train_state['stop_early'] = \\\n","        train_state['early_stopping_step'] >= args.early_stopping_criteria\n","  return train_state\n","\n","def compute_accuracy(y_pred, y_target):\n","  _, y_pred_indices = y_pred.max(dim=1)\n","  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","  return n_correct / len(y_pred_indices) * 100"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ig-lwAAkh0w"},"source":["###Initializations"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["13e5fc4be2cc419eba3b9e30e94e55d4","2d0b04795a3c48bcad1d44a1cbe897b6","3d848589526243089ebf867578bbcea4","daf53fb5efa547fab17532a19eda651b","90c7eaf603484860b39f65297aa88131","e6115bd7340344d2a5c790f042c59430","a352744b2cdb40458da8e4f003eb0950","43be67e825bb4040a9990a5745d665b1","ca00a8b3d73649b2a5c07c75d895b73e","4fe3bbab12b74bd6a9c6e38ee1ad7714","77a1998081604df0a47cc9190da4e525","d95d0dbd2e1448da9d317b244ccde3af","413035633579458fb69db5d0d2753353","ffacd5ee23c6479da5cd0919b9c59e91","8ede6e09ef4a45d3b5f86a9eb4a7025a","8cd621507b78480a8cc8e4efc500b95c"]},"id":"zhbuS8_ZkiE4","executionInfo":{"status":"ok","timestamp":1620467852605,"user_tz":-180,"elapsed":84978,"user":{"displayName":"Art-LesvosVillas Greece","photoUrl":"","userId":"06832438583615092524"}},"outputId":"4fa90729-061b-4035-c269-1b2fc31cd067"},"source":["if args.expand_filepaths_to_save_dir:\n","  args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n","  args.reload_name = os.path.join(args.save_dir, args.reload_name)\n","  print(\"Expanded filepaths: \")\n","  print(\"\\t{}\".format(args.model_state_file))\n","  print(\"\\t{}\".format(args.reload_name))\n","\n","# Set seed for reproducibility\n","set_seed_everywhere(args.seed, args.cuda)\n","\n","# handle dirs\n","# handle_dirs(args.save_dir)\n","\n","dataset = LegalDataset()\n","vectorizer = dataset.get_vectorizer()\n","classifier = LegalClassifier(no_classes=args.no_classes)\n","\n","if args.reload_from_files:\n","    # training from a checkpoint\n","    print(\"Reloading previous model!\")\n","    classifier.load_state_dict(torch.load(args.reload_name))\n","else:\n","    print(\"Creating fresh!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Expanded filepaths: \n","\t/content/drive/MyDrive/thesis/models/greek_BERT_replace_numbers/model_subject_numbers_replace.pth\n","\t/content/drive/MyDrive/thesis/models/greek_BERT_replace_numbers/model_volume_numbers_replace.pth\n","loading validation set...\n","loading training set...\n","loading test set...\n","Processing dataset...\n","Loading BERT tokenizer...\n","Calculating frequences...\n","Loading greek-Bert...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13e5fc4be2cc419eba3b9e30e94e55d4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=459.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca00a8b3d73649b2a5c07c75d895b73e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=454248854.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Creating fresh!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f1h5wBjHw_Gs"},"source":["###Training Loop"]},{"cell_type":"code","metadata":{"id":"lMdq50aOw_Mr"},"source":["if args.run_training:\n","  classifier = classifier.to(args.device)\n","  # dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","  loss_func = nn.CrossEntropyLoss()#weight=dataset.class_weights)\n","  optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n","                                                  mode='min', factor=0.5, patience=1)\n","\n","  train_state = make_train_state(args)\n","\n","  epoch_bar = tqdm(desc='training routine', \n","                            total=args.num_epochs,\n","                            position=0)\n","\n","  dataset.set_split('train')\n","  train_bar = tqdm(desc='split=train',\n","                            total=dataset.get_num_batches(args.batch_size), \n","                            position=1, \n","                            leave=True)\n","  dataset.set_split('val')\n","  val_bar = tqdm(desc='split=val',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","  try:\n","    for epoch_index in range(args.num_epochs):\n","      train_state['epoch_index'] = epoch_index\n","\n","      # Iterate over training dataset\n","\n","      # setup: batch generator, set loss and acc to 0, set train mode on\n","\n","      dataset.set_split('train')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.0\n","      running_acc = 0.0\n","      classifier.train()\n","\n","      for batch_index, batch_dict in enumerate(batch_generator):\n","        # the training routine is these 5 steps:\n","\n","        # --------------------------------------\n","        # step 1. zero the gradients\n","        optimizer.zero_grad()\n","        # step 2. compute the output\n","        y_pred = classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","        # step 3. compute the loss\n","        loss = loss_func(y_pred, batch_dict['target'])\n","        loss_t = loss.item()\n","        running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","        # step 4. use loss to produce gradients\n","        loss.backward()\n","\n","        # step 5. use optimizer to take gradient step\n","        optimizer.step()\n","        # -----------------------------------------\n","        # compute the accuracy\n","        acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","        running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","        # update bar\n","        train_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                        epoch=epoch_index)\n","        train_bar.update()\n","\n","      train_state['train_loss'].append(running_loss)\n","      train_state['train_acc'].append(running_acc)\n","\n","      # Iterate over val dataset\n","\n","      # setup: batch generator, set loss and acc to 0; set eval mode on\n","      dataset.set_split('val')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.\n","      running_acc = 0.\n","      classifier.eval()\n","      with torch.no_grad():\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","          # compute the output\n","          y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","\n","          # compute the loss\n","          loss = loss_func(y_pred, batch_dict['target'])\n","          loss_t = loss.to(\"cpu\").item()\n","          running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","          # compute the accuracy\n","          acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","          running_acc += (acc_t - running_acc) / (batch_index + 1)\n","          val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                          epoch=epoch_index)\n","          \n","          val_bar.update()\n","\n","      train_state['val_loss'].append(running_loss)\n","      train_state['val_acc'].append(running_acc)\n","\n","      train_state = update_train_state(args=args, model=classifier,\n","                                        train_state=train_state)\n","\n","      scheduler.step(train_state['val_loss'][-1])\n","\n","      if train_state['stop_early']:\n","        break\n","\n","      train_bar.n = 0\n","      val_bar.n = 0\n","      epoch_bar.update()\n","  except KeyboardInterrupt:\n","      print(\"Exiting loop\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOXfsB2Y69Bd"},"source":["### Testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f8402d6e11a3499ebb9a9af0193dccf8","4925dbcee08a475094c49fa1eb2616e2","05ec6082141f457e92be61cb6d52324f","49b75b3ece7c473eacebf130014538b0","4dfd79aa43a2472d8cfec24e1e97cecd","49ed70026c3a41e99cdfa012e0b88101","b73d0d6041b54ea093cb276883c49e5c","4e70437118dc41fca011d2706c9298c1"]},"id":"2ENl_kjXBEki","executionInfo":{"status":"ok","timestamp":1620468492848,"user_tz":-180,"elapsed":725198,"user":{"displayName":"Art-LesvosVillas Greece","photoUrl":"","userId":"06832438583615092524"}},"outputId":"323eb83b-13c6-41fa-c0f8-3281c26aca91"},"source":["# run test set and save results\n","\n","preds = []\n","correct = []\n","\n","classifier.load_state_dict(torch.load(args.model_state_file))\n","classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","\n","test_bar = tqdm(desc='split=test',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","classifier.eval()\n","with torch.no_grad():\n","  for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute output\n","    y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","    #save output\n","    preds += y_pred\n","    correct += batch_dict['target']\n","    test_bar.update()\n","\n","predictions = {'predictions' : preds,\n","              'correct' : correct}"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8402d6e11a3499ebb9a9af0193dccf8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=test', max=1189.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["fbd96e8c6b0549e38233182b9f96743b","d6d2fe660109445eb8edfd8e3ca2582c","6077214e544b4cc28c7eb48a75524398","a7092c11a89b449980b3046f241f6396","52b6a5e403d748f3920ee554d1bbbc9f","3fc849dee0e64f80a26e9611e0a3b482","d334e2f4283141adb3ef6c16048f3f05","dc396d4159cf4f4a9b6d100e3390eb51"]},"id":"aKIwkAS6UK1H","executionInfo":{"status":"ok","timestamp":1620468593200,"user_tz":-180,"elapsed":825531,"user":{"displayName":"Art-LesvosVillas Greece","photoUrl":"","userId":"06832438583615092524"}},"outputId":"fa3e4461-3faf-4417-92f3-924294436e4d"},"source":["# tensors to cpu and find predicted class\n","tmp = []\n","for item in tqdm(predictions['predictions'], desc='predictions to cpu'):\n","  item = item.cpu()\n","  tmp.append(item.tolist().index(max(item)))\n","predictions['predictions'] = tmp\n","predictions['correct'] = torch.tensor(predictions['correct'], device = 'cpu').tolist()\n","\n","frequent = {'predictions' : [],\n","            'correct' : []}\n","few_shot = {'predictions' : [],\n","            'correct' : []}\n","\n","for pred, target in zip(predictions['predictions'], predictions['correct']):\n","  if dataset.class_counts[target] < 10 and dataset.class_counts[target] != 0:\n","    few_shot['predictions'].append(pred)\n","    few_shot['correct'].append(target)\n","  elif dataset.class_counts[target] > 10:\n","    frequent['predictions'].append(pred)\n","    frequent['correct'].append(target)\n","\n","for group, dict_ in zip(['All     \\t','Frequent\\t','Fewshot \\t'], [predictions, frequent, few_shot]):\n","  if 'All' in group:\n","    l = list(set(dict_['correct']) | set(dict_['predictions']))\n","  else:\n","    l = list(set(dict_['correct']))\n","  f1 = round(f1_score(dict_['correct'], dict_['predictions'], average='micro', labels=l)*100,2)\n","  rec = round(recall_score(dict_['correct'], dict_['predictions'], average='micro', labels=l)*100,2)\n","  prec = round(precision_score(dict_['correct'], dict_['predictions'], average='micro', labels=l)*100,2)\n","  print(group+'\\t f1: '+str(f1)+'\\t recall: '+str(rec)+'\\t precision: '+str(prec))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbd96e8c6b0549e38233182b9f96743b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='predictions to cpu', max=9512.0, style=ProgressStyle(desc…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","All     \t\t f1: 74.91\t recall: 74.91\t precision: 74.91\n","Frequent\t\t f1: 81.94\t recall: 80.8\t precision: 83.12\n","Fewshot \t\t f1: 67.08\t recall: 55.01\t precision: 85.91\n"],"name":"stdout"}]}]}