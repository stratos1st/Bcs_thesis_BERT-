{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"no_numbers_Greek_bert.ipynb","provenance":[],"collapsed_sections":["4uHTL519iZVZ","nUbFqZMTYFOy","A89dNcfGViGB","t5SEw2hUfv5G","gMPeoqpOf7p3","oujVuInLieHc","_Ig-lwAAkh0w","f1h5wBjHw_Gs"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1758e5def29b486d85daee1465b458f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9564a74ae887459c83bc98b03f589495","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee42a83990fc492ebe4d8f2fe44f7eb6","IPY_MODEL_612a3ae869ed4e7486fc018926627d9b"]}},"9564a74ae887459c83bc98b03f589495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee42a83990fc492ebe4d8f2fe44f7eb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aad3b74b740945a3b227faa775eedbda","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":459,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":459,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8b1c19a5ca44128994a596b3e483691"}},"612a3ae869ed4e7486fc018926627d9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_16d022083baf45cfb406ea653bc10df2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 459/459 [00:00&lt;00:00, 3.39kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2508dc489ca4420f8991c349411cac9e"}},"aad3b74b740945a3b227faa775eedbda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8b1c19a5ca44128994a596b3e483691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"16d022083baf45cfb406ea653bc10df2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2508dc489ca4420f8991c349411cac9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bea7614f8a3b4f1aaebfbe11a96a8eaa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d79c385da2af4dd199fe318005403a73","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2f3e977d975348fcb893e04bb70e6da3","IPY_MODEL_7326ea7e7864446389cc96769701c9d2"]}},"d79c385da2af4dd199fe318005403a73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f3e977d975348fcb893e04bb70e6da3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_45c1bb803e5848ec879251175ce6dbb3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":529930,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":529930,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_937f081a563d451ca0e33baabf7a02fa"}},"7326ea7e7864446389cc96769701c9d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5871a14e2c3c487f92c4e66ef7ff3198","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 530k/530k [00:04&lt;00:00, 125kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb7dcaa599844a889a9c513f84812058"}},"45c1bb803e5848ec879251175ce6dbb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"937f081a563d451ca0e33baabf7a02fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5871a14e2c3c487f92c4e66ef7ff3198":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb7dcaa599844a889a9c513f84812058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0765c6d2bd845c6859b3a884c3bf6f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f1f2ba5565a14c5c981a01c89acb712d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9715c13740c4a2e9a407a642632c721","IPY_MODEL_27ffd83d22474ed6b42973fc28f3e3e2"]}},"f1f2ba5565a14c5c981a01c89acb712d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9715c13740c4a2e9a407a642632c721":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_64cf4e7e27b149eda6e2d9151a8451cd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c71b9f2794eb4e2a9dc9a7da1c0623c0"}},"27ffd83d22474ed6b42973fc28f3e3e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5c7377f45a6442daa5943cd1ad5dfb4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 134B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa6f7b95fc63490c985fbeb3f6e2e29c"}},"64cf4e7e27b149eda6e2d9151a8451cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c71b9f2794eb4e2a9dc9a7da1c0623c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5c7377f45a6442daa5943cd1ad5dfb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa6f7b95fc63490c985fbeb3f6e2e29c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74f19200d2664385bb6f5f81b9348628":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b001910d21b042c0aca42b67690758eb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a37eb1eac4e4540980ab65ed94aa2d2","IPY_MODEL_ff2c887cfbb3428b8d873830e9806ce3"]}},"b001910d21b042c0aca42b67690758eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a37eb1eac4e4540980ab65ed94aa2d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_053796093c9d4450a36e1823cc1710d4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb42cd3bccc944678c2bedfc518c558d"}},"ff2c887cfbb3428b8d873830e9806ce3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8fc4a5ca48b4bc887cca883211791b2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 18.9B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57fa430e869544ecb2314f10657c03f0"}},"053796093c9d4450a36e1823cc1710d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bb42cd3bccc944678c2bedfc518c558d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8fc4a5ca48b4bc887cca883211791b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57fa430e869544ecb2314f10657c03f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a0962c6be3842a6a56b97e77a42014d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f66b34870b9a462ca0b4d33e36253d48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_05b8fb1cbd894c77901e8e823fd41418","IPY_MODEL_ac5c5843375247d0b4bd20c4e782e438"]}},"f66b34870b9a462ca0b4d33e36253d48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05b8fb1cbd894c77901e8e823fd41418":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_88e7028893fa491492f14015c9e2e55d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":454248854,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":454248854,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8c47dbdaf9594157ae1fb5cd56675aa3"}},"ac5c5843375247d0b4bd20c4e782e438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_638453e8ae86402cae22ecaff3c43200","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 454M/454M [00:14&lt;00:00, 30.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_297b9edc5e2f45ecb324324d771c70d8"}},"88e7028893fa491492f14015c9e2e55d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8c47dbdaf9594157ae1fb5cd56675aa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"638453e8ae86402cae22ecaff3c43200":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"297b9edc5e2f45ecb324324d771c70d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c902490bfc4c44e189793cf02ad02659":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ba3b13c9c0084438a4500f313b034232","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14b4c34e7e81402ab043a58337ecb872","IPY_MODEL_cc73346b65d44ac4accdb8836f154d77"]}},"ba3b13c9c0084438a4500f313b034232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14b4c34e7e81402ab043a58337ecb872":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cfabed59a1f3496ebf5817464837fb7d","_dom_classes":[],"description":"split=test: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1189,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1189,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_78c3151291154d0eb3097ac4152c7d18"}},"cc73346b65d44ac4accdb8836f154d77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9f8c5ef084e64a91aebe01e990acaaf0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1189/1189 [10:41&lt;00:00,  1.81it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45aaaa18846e4b1ab59f0d35508991db"}},"cfabed59a1f3496ebf5817464837fb7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"78c3151291154d0eb3097ac4152c7d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f8c5ef084e64a91aebe01e990acaaf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"45aaaa18846e4b1ab59f0d35508991db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"EEDBycDQOHOY","executionInfo":{"status":"ok","timestamp":1618157828171,"user_tz":-180,"elapsed":3002,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["from argparse import Namespace\n","args = Namespace(\n","  # Data and path information\n","  dataset_path=\"/content/drive/MyDrive/thesis/dataset/\",\n","  model_state_file=\"model_chapter_numbers.pth\", \n","  save_dir=\"/content/drive/MyDrive/\", # save models here\n","  no_classes = 389, # subject 2285, chapter 389, volume 47\n","  class_name = 'chapter',\n","  # Training hyper parameters\n","  seed=1339,\n","  num_epochs=15,\n","  early_stopping_criteria=2,\n","  learning_rate=0.00002,\n","  batch_size=8,\n","  # Runtime options\n","  cuda=True,\n","  reload_from_files=True, # to continue training from checkpoint or evaluate a model\n","  reload_name=\"model_chapter_numbers.pth\",\n","  expand_filepaths_to_save_dir=True,\n","  run_training=False #if false it will run only on the test set\n",")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uHTL519iZVZ"},"source":["###tmp"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N1VlTthMldd","executionInfo":{"status":"ok","timestamp":1618157850887,"user_tz":-180,"elapsed":25705,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"d301f1eb-6d19-448b-bc06-eba79010afa0"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rqkz0Hg1O2Up","executionInfo":{"status":"ok","timestamp":1618157869636,"user_tz":-180,"elapsed":44448,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"3f5eaeab-a2f4-4fc5-e593-8b3b9247eac3"},"source":["# from collections import Counter\n","from string import digits\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","from tqdm import trange\n","\n","!pip install torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","print('Loading torchmetrics lib...')\n","# https://torchmetrics.readthedocs.io/en/latest/index.html\n","!pip install torchmetrics\n","from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1\n","\n","# reading json files\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","\n","# huggingface lib bert\n","print('Loading transformers lib...')\n","!pip install transformers\n","from transformers import AutoTokenizer, AutoModel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Loading torchmetrics lib...\n","Collecting torchmetrics\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/42/d984612cabf005a265aa99c8d4ab2958e37b753aafb12f31c81df38751c8/torchmetrics-0.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.2.0\n","Loading transformers lib...\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n","\u001b[K     |████████████████████████████████| 870kB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 38.0MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=ae222c877036fa34e7840b206e9f6a5ed662c1b990d1aa7ea9cfc0d234c40b3c\n","  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VlFvFQUvOAcZ","executionInfo":{"status":"ok","timestamp":1618157869637,"user_tz":-180,"elapsed":44442,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"fa26fcf1-a19a-477e-9b3e-6439789cb637"},"source":["# Check CUDA and gpu available\n","if not torch.cuda.is_available():\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Using CUDA: {}\".format(args.cuda))\n","if args.cuda:\n","  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using CUDA: True\n","GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nUbFqZMTYFOy"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"x5SVi3W8YFUb","executionInfo":{"status":"ok","timestamp":1618157869638,"user_tz":-180,"elapsed":44441,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# sets the seed everywhere for reprodusable results\n","def set_seed_everywhere(seed, cuda):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  # random.seed(seed)\n","  # !!!! may need to add hugingface init seed\n","  if cuda:\n","    torch.cuda.manual_seed_all(seed)\n","\n","# creates non existing directories\n","def handle_dirs(dirpath):\n","  if not os.path.exists(dirpath):\n","    os.makedirs(dirpath)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A89dNcfGViGB"},"source":["### The Vectorizer"]},{"cell_type":"code","metadata":{"id":"8jG3SJWzViOn","executionInfo":{"status":"ok","timestamp":1618157869643,"user_tz":-180,"elapsed":44443,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalVectorizer(object):\n","  \"\"\" The Vectorizer\"\"\"\n","  def __init__(self):\n","    print('Loading BERT tokenizer...')\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\",\n","                                                   model_max_length=512, use_fast=True)\n","\n","  def vectorize(self, text):\n","    \"\"\"\n","    Args:\n","        text (list of str):\n","    Returns:\n","        dictionary: \"vector\" is a tensor with a list of encoded text paded to max_len, ready for import to BERT\n","                    \"mask\" is a tensor with a list of masks ready for import to BERT\n","    \"\"\"\n","    encoded_dict = self.tokenizer(\n","                    text,                      \n","                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                    padding = True, # pad to longest in batch\n","                    truncation = True, # truncates sentenses to 512, max bert length\n","                    # padding = 'max_length',\n","                    # max_length = 512,           # Pad\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',     # Return pytorch tensors.\n","                )\n","    return {\"vector\" : encoded_dict['input_ids'],\n","            \"mask\" : encoded_dict['attention_mask']}\n","\n","  def get_pad_tocken(self):\n","    return self.tokenizer.pad_token_id\n","\n","  def to_words(self, vector, remove_pads=True):\n","    \"\"\"\n","    Args:\n","        vector (tensor): list of vectors to decode\n","        remove_pads : remove pad \n","    Returns:\n","        list of lists of words coresponding to the vector values\n","    \"\"\"\n","    if remove_pads:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v[v.nonzero()]) for v in vector]\n","    else:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v) for v in vector]\n","    return ans\n","      "],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CL6zGRvng0cb"},"source":["###The dataset"]},{"cell_type":"code","metadata":{"id":"9OVA8YQTg0QD","executionInfo":{"status":"ok","timestamp":1618157869645,"user_tz":-180,"elapsed":44442,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalDataset(Dataset):\n","  def __init__(self):\n","    print(\"loading validation set...\")\n","    self.val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","    self.validation_size = len(self.val_df)\n","    print(\"loading training set...\")\n","    self.train_df = pd.read_pickle(args.dataset_path + \"train.pkl\")\n","    self.train_size = len(self.train_df)\n","    print(\"loading test set...\")\n","    self.test_df = pd.read_pickle(args.dataset_path + \"test.pkl\")\n","    self.test_size = len(self.test_df)\n","    # check the dataset size (dataset has extra files when uploaded to google drive. it mekes copies ex. \"123 (1).json\")\n","    if self.val_df.shape[0]!=9511 or self.train_df.shape[0]!=28536 or self.test_df.shape[0]!=9516:\n","      print(self.val_df.shape[0])\n","      print(self.train_df.shape[0])\n","      print(self.test_df.shape[0])\n","      print(\"!! ERROR dataset size !!\")\n","      exit()\n","\n","    print(\"Processing dataset...\")\n","    # replace class names with 0...n numbers\n","    class_namess = pd.concat([ self.val_df[args.class_name],\n","                             self.train_df[args.class_name],\n","                             self.test_df[args.class_name] ]).unique()\n","    self.class_names = dict(zip(class_namess, range(len(class_namess))))\n","    self.val_df[args.class_name] = self.val_df[args.class_name].replace(self.class_names)\n","    self.train_df[args.class_name] = self.train_df[args.class_name].replace(self.class_names)\n","    self.test_df[args.class_name] = self.test_df[args.class_name].replace(self.class_names)\n","    # delete usless stuff\n","    self.val_df = self.val_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.train_df = self.train_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.test_df = self.test_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","\n","    self._vectorizer = LegalVectorizer()\n","    self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                          'val': (self.val_df, self.validation_size),\n","                          'test': (self.test_df, self.test_size)}\n","\n","    self.set_split('train')\n","\n","    print(\"Calculating frequences...\")\n","    self.class_counts = []\n","    for v in range(args.no_classes):\n","      tmp = self.train_df[self.train_df[args.class_name]==v][args.class_name].count()\n","      if tmp>0:\n","        self.class_counts.append(tmp)\n","      else:\n","        self.class_counts.append(0)\n","    # self.class_weights = 10000.0 / torch.tensor(self.class_counts, dtype=torch.float32) \n","\n","  def get_vectorizer(self):\n","    \"\"\" returns the vectorizer \"\"\"\n","    return self._vectorizer\n","\n","  def set_split(self, split):\n","    \"\"\" selects the splits in the dataset using _lookup_dict \"\"\"\n","    # self._target_split = split\n","    self._target_df, self._target_size = self._lookup_dict[split]\n","\n","  def __len__(self):\n","    return self._target_size\n","\n","  def __getitem__(self, index):\n","    \"\"\"the primary entry point method for PyTorch datasets\n","    Args:\n","        index (int): the index to the data point \n","    Returns:\n","        a dictionary holding the data point's. text is NOT vectorized yet.\n","    \"\"\"\n","    row = self._target_df.iloc[index]\n","    target = row[args.class_name]\n","    tmp = row['header'] + ' ' + row['articles']\n","    remove_digits = str.maketrans('', '', digits)\n","    text = tmp.translate(remove_digits)\n","\n","    return {'target': target,\n","            'text' : text}\n","      \n","  def get_num_batches(self, batch_size):\n","    \"\"\"Given a batch size, return the number of batches in the dataset\n","    Args:\n","      batch_size (int)\n","    Returns:\n","      number of batches in the dataset\n","    \"\"\"\n","    return len(self) // batch_size"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5SEw2hUfv5G"},"source":["###Dataloader"]},{"cell_type":"code","metadata":{"id":"-q4zXTEffv_V","executionInfo":{"status":"ok","timestamp":1618157869646,"user_tz":-180,"elapsed":44441,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# this is a cool way to save some time in training. Havent done it yet, may effect accuracy\n","# http://mccormickml.com/2020/07/29/smart-batching-tutorial\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"): \n","  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                          shuffle=shuffle, drop_last=drop_last)\n","\n","  for data_dict in dataloader:\n","    #vectorize batch text\n","    tmp = dataset.get_vectorizer().vectorize(data_dict['text'])\n","    mask, vector = tmp['mask'], tmp['vector']\n","    data_dict['vector'] = vector\n","    data_dict['mask'] = mask\n","    del data_dict['text']\n","\n","    out_data_dict = {}\n","    for name, tensor in data_dict.items():\n","        out_data_dict[name] = data_dict[name].to(device)\n","    yield out_data_dict"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMPeoqpOf7p3"},"source":["###The Model"]},{"cell_type":"code","metadata":{"id":"3GJCeb23f7wa","executionInfo":{"status":"ok","timestamp":1618157869647,"user_tz":-180,"elapsed":44435,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalClassifier(nn.Module):\n","  \"\"\" greek-Bert model with an extra linear layer, which takes \n","      the cls tocken as input, for classification \"\"\"\n","  def __init__(self, no_classes):\n","    \"\"\"\n","    Args:\n","        no_classes (int): the size of the linear layer\n","    \"\"\"\n","    super(LegalClassifier, self).__init__()\n","    print(\"Loading greek-Bert...\")\n","    self.bert = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","    self.dropout = nn.Dropout(0.1)\n","    self.fc = nn.Linear(768,no_classes)\n","    # for param in self.bert.parameters():\n","    #   param.requires_grad = False\n","\n","  def forward(self, input, mask, apply_softmax=False):\n","    \"\"\"The forward pass of the classifier\n","    Args:\n","        input (torch.Tensor): an input data tensor.\n","        mask (torch.Tensor): the coresponding masks for BERT\n","        apply_softmax (bool): whether or not to apply soflmax to the output layer\n","    Returns:\n","        the resulting tensor. tensor.shape should be (batch, output_dim)\n","    \"\"\"\n","    output = self.bert(input_ids=input, attention_mask=mask, \n","                       output_attentions=False, output_hidden_states=False)\n","    x = output.pooler_output # coresponds to CLS token\n","    x = self.dropout(x) \n","    x = self.fc(x)\n","    if apply_softmax:\n","        x = F.softmax(x, dim=1)\n","    return x"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oujVuInLieHc"},"source":["###helper functions"]},{"cell_type":"code","metadata":{"id":"wEbV1KG-ieOs","executionInfo":{"status":"ok","timestamp":1618157869647,"user_tz":-180,"elapsed":44432,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def make_train_state(args):\n","  return {'stop_early': False,\n","          'early_stopping_step': 0,\n","          'early_stopping_best_val': 1e8,\n","          'learning_rate': args.learning_rate,\n","          'epoch_index': 0,\n","          'train_loss': [],\n","          'train_acc': [],\n","          'val_loss': [],\n","          'val_acc': [],\n","          'test_loss': -1,\n","          'test_acc': -1,\n","          'model_filename': args.model_state_file}\n","\n","def update_train_state(args, model, train_state):\n","  \"\"\"Handle the training state updates.\n","\n","  Components:\n","    - Early Stopping: Prevent overfitting.\n","    - Model Checkpoint: Model is saved if the model is better\n","\n","  :param args: main arguments\n","  :param model: model to train\n","  :param train_state: a dictionary representing the training state values\n","  :returns:\n","      a new train_state\n","  \"\"\"\n","  # Save one model at least\n","  if train_state['epoch_index'] == 0:\n","    torch.save(model.state_dict(), train_state['model_filename'])\n","    train_state['stop_early'] = False\n","\n","  # Save model if performance improved\n","  elif train_state['epoch_index'] >= 1:\n","    loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","    # If loss worsened\n","    if loss_t >= train_state['early_stopping_best_val']:\n","      # Update step\n","      train_state['early_stopping_step'] += 1\n","    # Loss decreased\n","    else:\n","      # Save the best model\n","      if loss_t < train_state['early_stopping_best_val']:\n","          torch.save(model.state_dict(), train_state['model_filename'])\n","      # Reset early stopping step\n","      train_state['early_stopping_step'] = 0\n","\n","    # Stop early ?\n","    train_state['stop_early'] = \\\n","        train_state['early_stopping_step'] >= args.early_stopping_criteria\n","  return train_state\n","\n","def compute_accuracy(y_pred, y_target):\n","  _, y_pred_indices = y_pred.max(dim=1)\n","  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","  return n_correct / len(y_pred_indices) * 100"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ig-lwAAkh0w"},"source":["###Initializations"]},{"cell_type":"code","metadata":{"id":"zhbuS8_ZkiE4","colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["1758e5def29b486d85daee1465b458f3","9564a74ae887459c83bc98b03f589495","ee42a83990fc492ebe4d8f2fe44f7eb6","612a3ae869ed4e7486fc018926627d9b","aad3b74b740945a3b227faa775eedbda","c8b1c19a5ca44128994a596b3e483691","16d022083baf45cfb406ea653bc10df2","2508dc489ca4420f8991c349411cac9e","bea7614f8a3b4f1aaebfbe11a96a8eaa","d79c385da2af4dd199fe318005403a73","2f3e977d975348fcb893e04bb70e6da3","7326ea7e7864446389cc96769701c9d2","45c1bb803e5848ec879251175ce6dbb3","937f081a563d451ca0e33baabf7a02fa","5871a14e2c3c487f92c4e66ef7ff3198","fb7dcaa599844a889a9c513f84812058","d0765c6d2bd845c6859b3a884c3bf6f9","f1f2ba5565a14c5c981a01c89acb712d","b9715c13740c4a2e9a407a642632c721","27ffd83d22474ed6b42973fc28f3e3e2","64cf4e7e27b149eda6e2d9151a8451cd","c71b9f2794eb4e2a9dc9a7da1c0623c0","f5c7377f45a6442daa5943cd1ad5dfb4","fa6f7b95fc63490c985fbeb3f6e2e29c","74f19200d2664385bb6f5f81b9348628","b001910d21b042c0aca42b67690758eb","8a37eb1eac4e4540980ab65ed94aa2d2","ff2c887cfbb3428b8d873830e9806ce3","053796093c9d4450a36e1823cc1710d4","bb42cd3bccc944678c2bedfc518c558d","d8fc4a5ca48b4bc887cca883211791b2","57fa430e869544ecb2314f10657c03f0","6a0962c6be3842a6a56b97e77a42014d","f66b34870b9a462ca0b4d33e36253d48","05b8fb1cbd894c77901e8e823fd41418","ac5c5843375247d0b4bd20c4e782e438","88e7028893fa491492f14015c9e2e55d","8c47dbdaf9594157ae1fb5cd56675aa3","638453e8ae86402cae22ecaff3c43200","297b9edc5e2f45ecb324324d771c70d8"]},"executionInfo":{"status":"ok","timestamp":1618157926812,"user_tz":-180,"elapsed":101592,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"27ca8630-92ef-43f5-ebab-fa30c245cb91"},"source":["if args.expand_filepaths_to_save_dir:\n","  args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n","  args.reload_name = os.path.join(args.save_dir, args.reload_name)\n","  print(\"Expanded filepaths: \")\n","  print(\"\\t{}\".format(args.model_state_file))\n","  print(\"\\t{}\".format(args.reload_name))\n","\n","# Set seed for reproducibility\n","set_seed_everywhere(args.seed, args.cuda)\n","\n","# handle dirs\n","# handle_dirs(args.save_dir)\n","\n","dataset = LegalDataset()\n","vectorizer = dataset.get_vectorizer()\n","classifier = LegalClassifier(no_classes=args.no_classes)\n","\n","if args.reload_from_files:\n","    # training from a checkpoint\n","    print(\"Reloading previous model!\")\n","    classifier.load_state_dict(torch.load(args.reload_name))\n","else:\n","    print(\"Creating fresh!\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Expanded filepaths: \n","\t/content/drive/MyDrive/model_chapter_numbers.pth\n","\t/content/drive/MyDrive/model_chapter_numbers.pth\n","loading validation set...\n","loading training set...\n","loading test set...\n","Processing dataset...\n","Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1758e5def29b486d85daee1465b458f3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=459.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bea7614f8a3b4f1aaebfbe11a96a8eaa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=529930.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0765c6d2bd845c6859b3a884c3bf6f9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74f19200d2664385bb6f5f81b9348628","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Calculating frequences...\n","Loading greek-Bert...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a0962c6be3842a6a56b97e77a42014d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=454248854.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Reloading previous model!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f1h5wBjHw_Gs"},"source":["###Training Loop"]},{"cell_type":"code","metadata":{"id":"lMdq50aOw_Mr","executionInfo":{"status":"ok","timestamp":1618157927288,"user_tz":-180,"elapsed":102066,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["if args.run_training:\n","  classifier = classifier.to(args.device)\n","  # dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","  loss_func = nn.CrossEntropyLoss()#weight=dataset.class_weights)\n","  optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n","                                                  mode='min', factor=0.5, patience=1)\n","\n","  train_state = make_train_state(args)\n","\n","  epoch_bar = tqdm(desc='training routine', \n","                            total=args.num_epochs,\n","                            position=0)\n","\n","  dataset.set_split('train')\n","  train_bar = tqdm(desc='split=train',\n","                            total=dataset.get_num_batches(args.batch_size), \n","                            position=1, \n","                            leave=True)\n","  dataset.set_split('val')\n","  val_bar = tqdm(desc='split=val',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","  try:\n","    for epoch_index in range(args.num_epochs):\n","      train_state['epoch_index'] = epoch_index\n","\n","      # Iterate over training dataset\n","\n","      # setup: batch generator, set loss and acc to 0, set train mode on\n","\n","      dataset.set_split('train')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.0\n","      running_acc = 0.0\n","      classifier.train()\n","\n","      for batch_index, batch_dict in enumerate(batch_generator):\n","        # the training routine is these 5 steps:\n","\n","        # --------------------------------------\n","        # step 1. zero the gradients\n","        optimizer.zero_grad()\n","        # step 2. compute the output\n","        y_pred = classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","        # step 3. compute the loss\n","        loss = loss_func(y_pred, batch_dict['target'])\n","        loss_t = loss.item()\n","        running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","        # step 4. use loss to produce gradients\n","        loss.backward()\n","\n","        # step 5. use optimizer to take gradient step\n","        optimizer.step()\n","        # -----------------------------------------\n","        # compute the accuracy\n","        acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","        running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","        # update bar\n","        train_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                        epoch=epoch_index)\n","        train_bar.update()\n","\n","      train_state['train_loss'].append(running_loss)\n","      train_state['train_acc'].append(running_acc)\n","\n","      # Iterate over val dataset\n","\n","      # setup: batch generator, set loss and acc to 0; set eval mode on\n","      dataset.set_split('val')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.\n","      running_acc = 0.\n","      classifier.eval()\n","      with torch.no_grad():\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","          # compute the output\n","          y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","\n","          # compute the loss\n","          loss = loss_func(y_pred, batch_dict['target'])\n","          loss_t = loss.to(\"cpu\").item()\n","          running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","          # compute the accuracy\n","          acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","          running_acc += (acc_t - running_acc) / (batch_index + 1)\n","          val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                          epoch=epoch_index)\n","          \n","          val_bar.update()\n","\n","      train_state['val_loss'].append(running_loss)\n","      train_state['val_acc'].append(running_acc)\n","\n","      train_state = update_train_state(args=args, model=classifier,\n","                                        train_state=train_state)\n","\n","      scheduler.step(train_state['val_loss'][-1])\n","\n","      if train_state['stop_early']:\n","        break\n","\n","      train_bar.n = 0\n","      val_bar.n = 0\n","      epoch_bar.update()\n","  except KeyboardInterrupt:\n","      print(\"Exiting loop\")"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOXfsB2Y69Bd"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"2ENl_kjXBEki","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c902490bfc4c44e189793cf02ad02659","ba3b13c9c0084438a4500f313b034232","14b4c34e7e81402ab043a58337ecb872","cc73346b65d44ac4accdb8836f154d77","cfabed59a1f3496ebf5817464837fb7d","78c3151291154d0eb3097ac4152c7d18","9f8c5ef084e64a91aebe01e990acaaf0","45aaaa18846e4b1ab59f0d35508991db"]},"executionInfo":{"status":"ok","timestamp":1618158569477,"user_tz":-180,"elapsed":744247,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"d43b4d23-81fb-4d7e-9a4f-c7c92cc26065"},"source":["# run test set and save results\n","\n","predictions = []\n","correct = []\n","\n","classifier.load_state_dict(torch.load(args.model_state_file))\n","classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","\n","test_bar = tqdm(desc='split=test',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","classifier.eval()\n","with torch.no_grad():\n","  for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute output\n","    y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","    #save output\n","    predictions += y_pred\n","    correct += batch_dict['target']\n","    test_bar.update()\n","\n","predictions = {'predictions' : predictions,\n","              'correct' : correct}\n","# with open(args.save_dir+\"model_predictions/\"+args.class_name+\".pkl\", 'wb') as handle:\n","#     pickle.dump(ans, handle)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c902490bfc4c44e189793cf02ad02659","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=test', max=1189.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"aKIwkAS6UK1H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618158571536,"user_tz":-180,"elapsed":746301,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"1e166494-86ef-4e12-be9d-0b06d3a9de9e"},"source":["# handle = open(args.save_dir+\"model_predictions/\"+args.class_name+\".pkl\", 'rb')\n","# predictions = pickle.load(handle)\n","\n","metric_collection = MetricCollection([\n","  Accuracy(),\n","  Precision(num_classes=args.no_classes, average='macro'),\n","  Recall(num_classes=args.no_classes, average='macro'),\n","  F1(num_classes=args.no_classes, average='micro')\n","]).to(args.device)\n","\n","frequent = {'predictions' : [],\n","            'correct' : []}\n","few_shot = {'predictions' : [],\n","            'correct' : []}\n","all = {'predictions' : [],\n","            'correct' : []}\n","\n","for pred, target in zip(predictions['predictions'], predictions['correct']):\n","  if dataset.class_counts[target] < 10 and dataset.class_counts[target] != 0:\n","    few_shot['predictions'].append(pred)\n","    few_shot['correct'].append(target)\n","  elif dataset.class_counts[target] > 10:\n","    frequent['predictions'].append(pred)\n","    frequent['correct'].append(target)\n","  if dataset.class_counts[target] != 0:\n","    all['predictions'].append(pred)\n","    all['correct'].append(target)\n","\n","metric_collection.update(torch.stack(predictions['predictions']), torch.stack(predictions['correct']))\n","print(\"All labels\\t\"+str(metric_collection.compute()))\n","metric_collection.reset()\n","metric_collection.update(torch.stack(all['predictions']), torch.stack(all['correct']))\n","print(\"All-0 labels\\t\"+str(metric_collection.compute()))\n","metric_collection.reset()\n","metric_collection.update(torch.stack(frequent['predictions']), torch.stack(frequent['correct']))\n","print(\"Frequent\\t\"+str(metric_collection.compute()))\n","metric_collection.reset()\n","metric_collection.update(torch.stack(few_shot['predictions']), torch.stack(few_shot['correct']))\n","print(\"Few_shot\\t\"+str(metric_collection.compute()))\n","metric_collection.reset()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["All labels\t{'Accuracy': tensor(0.8115, device='cuda:0'), 'Precision': tensor(0.6856, device='cuda:0'), 'Recall': tensor(0.6594, device='cuda:0'), 'F1': tensor(0.8115, device='cuda:0')}\n","All-0 labels\t{'Accuracy': tensor(0.8118, device='cuda:0'), 'Precision': tensor(0.6860, device='cuda:0'), 'Recall': tensor(0.6594, device='cuda:0'), 'F1': tensor(0.8118, device='cuda:0')}\n","Frequent\t{'Accuracy': tensor(0.8182, device='cuda:0'), 'Precision': tensor(0.6710, device='cuda:0'), 'Recall': tensor(0.6407, device='cuda:0'), 'F1': tensor(0.8182, device='cuda:0')}\n","Few_shot\t{'Accuracy': tensor(0.1702, device='cuda:0'), 'Precision': tensor(0.0197, device='cuda:0'), 'Recall': tensor(0.0136, device='cuda:0'), 'F1': tensor(0.1702, device='cuda:0')}\n"],"name":"stdout"}]}]}