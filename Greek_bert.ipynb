{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Greek_bert.ipynb","provenance":[],"collapsed_sections":["4uHTL519iZVZ","nUbFqZMTYFOy","A89dNcfGViGB","CL6zGRvng0cb","t5SEw2hUfv5G","gMPeoqpOf7p3","oujVuInLieHc","_Ig-lwAAkh0w","f1h5wBjHw_Gs"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4078bdfcc660446fb50e216a07771a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2041f8b0d8184243814a46320b6dc52e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72da06141da94c819cc3b112d5182cc3","IPY_MODEL_103c13f46af44ee790e8c90b69ba7170"]}},"2041f8b0d8184243814a46320b6dc52e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72da06141da94c819cc3b112d5182cc3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3c1cabe5f74543d3b483c22da4fde018","_dom_classes":[],"description":"split=test: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1189,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1189,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8156bc91118e437aa1e7c85d54e67abe"}},"103c13f46af44ee790e8c90b69ba7170":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f15d5f6cd780406eaacaacfdf2fed79d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1189/1189 [05:45&lt;00:00,  3.29it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f9d12e1c34748ed8a9caa013e8f8676"}},"3c1cabe5f74543d3b483c22da4fde018":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8156bc91118e437aa1e7c85d54e67abe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f15d5f6cd780406eaacaacfdf2fed79d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f9d12e1c34748ed8a9caa013e8f8676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95afca66e6954ae39d96c27465cad075":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ff54fcdcc2344e789c14bd1858c6d7c0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_716f44373fa3423695baee9e3c972771","IPY_MODEL_04af7c9fe0ad46f0a632b2a57264b08c"]}},"ff54fcdcc2344e789c14bd1858c6d7c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"716f44373fa3423695baee9e3c972771":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_95a26540c92d4f42a5edca20d51d5913","_dom_classes":[],"description":"predictions to cpu: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":9512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b520efca941846b589cc3f931ab61677"}},"04af7c9fe0ad46f0a632b2a57264b08c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_21ad18ab1601494db6a2e7eba64988d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9512/9512 [00:18&lt;00:00, 517.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_285817da7f94499db08bac4900725d32"}},"95a26540c92d4f42a5edca20d51d5913":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b520efca941846b589cc3f931ab61677":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21ad18ab1601494db6a2e7eba64988d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"285817da7f94499db08bac4900725d32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"EEDBycDQOHOY","executionInfo":{"status":"ok","timestamp":1618250956623,"user_tz":-180,"elapsed":648,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["from argparse import Namespace\n","args = Namespace(\n","  # Data and path information\n","  dataset_path=\"/content/drive/MyDrive/thesis/dataset/\",\n","  model_state_file=\"model_chapter_8.pth\", \n","  save_dir=\"/content/drive/MyDrive/thesis/models/greek-BERT/\", # save models here\n","  no_classes = 389, # subject 2285, chapter 389, volume 47\n","  class_name = 'chapter',\n","  # Training hyper parameters\n","  seed=1338,\n","  num_epochs=15,\n","  early_stopping_criteria=2,\n","  learning_rate=0.00002,\n","  batch_size=8,\n","  # Runtime options\n","  cuda=True,\n","  reload_from_files=True, # to continue training from checkpoint or evaluate a model\n","  reload_name=\"model_chapter_8.pth\",\n","  expand_filepaths_to_save_dir=True,\n","  run_training=False #if false it will run only on the test set\n",")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uHTL519iZVZ"},"source":["###tmp"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N1VlTthMldd","executionInfo":{"status":"ok","timestamp":1618250956861,"user_tz":-180,"elapsed":875,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"aa2654bc-79fa-446a-f8b2-7b2148497bc1"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rqkz0Hg1O2Up","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618250962691,"user_tz":-180,"elapsed":6700,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"2834425e-f457-42c4-d563-bdb1c173af35"},"source":["# from collections import Counter\n","# import string\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","!pip install torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","print('Loading torchmetrics lib...')\n","# # https://torchmetrics.readthedocs.io/en/latest/index.html\n","# !pip install torchmetrics\n","# from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1\n","from sklearn.metrics import f1_score, recall_score, precision_score\n","\n","# reading json files\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","\n","# huggingface lib bert\n","print('Loading transformers lib...')\n","!pip install transformers\n","from transformers import AutoTokenizer, AutoModel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Loading torchmetrics lib...\n","Loading transformers lib...\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VlFvFQUvOAcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618250963050,"user_tz":-180,"elapsed":7054,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"ffe8b5f7-6b06-4acf-c314-3844a8be2c13"},"source":["# Check CUDA and gpu available\n","if not torch.cuda.is_available():\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Using CUDA: {}\".format(args.cuda))\n","if args.cuda:\n","  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using CUDA: True\n","GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nUbFqZMTYFOy"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"x5SVi3W8YFUb","executionInfo":{"status":"ok","timestamp":1618250963050,"user_tz":-180,"elapsed":7050,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# sets the seed everywhere for reprodusable results\n","def set_seed_everywhere(seed, cuda):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  # random.seed(seed)\n","  # !!!! may need to add hugingface init seed\n","  if cuda:\n","    torch.cuda.manual_seed_all(seed)\n","\n","# creates non existing directories\n","def handle_dirs(dirpath):\n","  if not os.path.exists(dirpath):\n","    os.makedirs(dirpath)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A89dNcfGViGB"},"source":["### The Vectorizer"]},{"cell_type":"code","metadata":{"id":"8jG3SJWzViOn","executionInfo":{"status":"ok","timestamp":1618250963052,"user_tz":-180,"elapsed":7047,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalVectorizer(object):\n","  \"\"\" The Vectorizer\"\"\"\n","  def __init__(self):\n","    print('Loading BERT tokenizer...')\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\", \n","                                                    model_max_length=512, use_fast=True)\n","\n","  def vectorize(self, text):\n","    \"\"\"\n","    Args:\n","        text (list of str):\n","    Returns:\n","        dictionary: \"vector\" is a tensor with a list of encoded text paded to max_len, ready for import to BERT\n","                    \"mask\" is a tensor with a list of masks ready for import to BERT\n","    \"\"\"\n","    encoded_dict = self.tokenizer(\n","                    text,                      \n","                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                    padding = True, # pad to longest in batch\n","                    truncation = True, # truncates sentenses to 512, max bert length\n","                    # padding = 'max_length',\n","                    # max_length = 512,           # Pad\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',     # Return pytorch tensors.\n","                )\n","    return {\"vector\" : encoded_dict['input_ids'],\n","            \"mask\" : encoded_dict['attention_mask']}\n","\n","  def get_pad_tocken(self):\n","    return self.tokenizer.pad_token_id\n","\n","  def to_words(self, vector, remove_pads=True):\n","    \"\"\"\n","    Args:\n","        vector (tensor): list of vectors to decode\n","        remove_pads : remove pad \n","    Returns:\n","        list of lists of words coresponding to the vector values\n","    \"\"\"\n","    if remove_pads:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v[v.nonzero()]) for v in vector]\n","    else:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v) for v in vector]\n","    return ans\n","      "],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CL6zGRvng0cb"},"source":["###The dataset"]},{"cell_type":"code","metadata":{"id":"9OVA8YQTg0QD","executionInfo":{"status":"ok","timestamp":1618250963057,"user_tz":-180,"elapsed":7048,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalDataset(Dataset):\n","  def __init__(self):\n","    print(\"loading validation set...\")\n","    self.val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","    self.validation_size = len(self.val_df)\n","    print(\"loading training set...\")\n","    self.train_df = pd.read_pickle(args.dataset_path + \"train.pkl\")\n","    self.train_size = len(self.train_df)\n","    print(\"loading test set...\")\n","    self.test_df = pd.read_pickle(args.dataset_path + \"test.pkl\")\n","    self.test_size = len(self.test_df)\n","    # check the dataset size (dataset has extra files when uploaded to google drive. it mekes copies ex. \"123 (1).json\")\n","    if self.val_df.shape[0]!=9511 or self.train_df.shape[0]!=28536 or self.test_df.shape[0]!=9516:\n","      print(self.val_df.shape[0])\n","      print(self.train_df.shape[0])\n","      print(self.test_df.shape[0])\n","      print(\"!! ERROR dataset size !!\")\n","      exit()\n","\n","    print(\"Processing dataset...\")\n","    # replace class names with 0...n numbers\n","    class_namess = pd.concat([ self.val_df[args.class_name],\n","                             self.train_df[args.class_name],\n","                             self.test_df[args.class_name] ]).unique()\n","    self.class_names = dict(zip(class_namess, range(len(class_namess))))\n","    self.val_df[args.class_name] = self.val_df[args.class_name].replace(self.class_names)\n","    self.train_df[args.class_name] = self.train_df[args.class_name].replace(self.class_names)\n","    self.test_df[args.class_name] = self.test_df[args.class_name].replace(self.class_names)\n","    # delete usless stuff\n","    self.val_df = self.val_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.train_df = self.train_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.test_df = self.test_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","\n","    self._vectorizer = LegalVectorizer()\n","    self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                          'val': (self.val_df, self.validation_size),\n","                          'test': (self.test_df, self.test_size)}\n","\n","    self.set_split('train')\n","\n","    print(\"Calculating frequences...\")\n","    self.class_counts = []\n","    for v in range(args.no_classes):\n","      tmp = self.train_df[self.train_df[args.class_name]==v][args.class_name].count()\n","      if tmp>0:\n","        self.class_counts.append(tmp)\n","      else:\n","        self.class_counts.append(0)\n","    # self.class_weights = 10000.0 / torch.tensor(self.class_counts, dtype=torch.float32) \n","\n","  def get_vectorizer(self):\n","    \"\"\" returns the vectorizer \"\"\"\n","    return self._vectorizer\n","\n","  def set_split(self, split):\n","    \"\"\" selects the splits in the dataset using _lookup_dict \"\"\"\n","    # self._target_split = split\n","    self._target_df, self._target_size = self._lookup_dict[split]\n","\n","  def __len__(self):\n","    return self._target_size\n","\n","  def __getitem__(self, index):\n","    \"\"\"the primary entry point method for PyTorch datasets\n","    Args:\n","        index (int): the index to the data point \n","    Returns:\n","        a dictionary holding the data point's. text is NOT vectorized yet.\n","    \"\"\"\n","    row = self._target_df.iloc[index]\n","    target = row[args.class_name]\n","    text = row['header'] + ' ' + row['articles']\n","\n","    return {'target': target,\n","            'text' : text}\n","      \n","  def get_num_batches(self, batch_size):\n","    \"\"\"Given a batch size, return the number of batches in the dataset\n","    Args:\n","      batch_size (int)\n","    Returns:\n","      number of batches in the dataset\n","    \"\"\"\n","    return len(self) // batch_size"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5SEw2hUfv5G"},"source":["###Dataloader"]},{"cell_type":"code","metadata":{"id":"-q4zXTEffv_V","executionInfo":{"status":"ok","timestamp":1618250963058,"user_tz":-180,"elapsed":7042,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# this is a cool way to save some time in training. Havent done it yet, may effect accuracy\n","# http://mccormickml.com/2020/07/29/smart-batching-tutorial\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"): \n","  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                          shuffle=shuffle, drop_last=drop_last)\n","\n","  for data_dict in dataloader:\n","    #vectorize batch text\n","    tmp = dataset.get_vectorizer().vectorize(data_dict['text'])\n","    mask, vector = tmp['mask'], tmp['vector']\n","    data_dict['vector'] = vector\n","    data_dict['mask'] = mask\n","    del data_dict['text']\n","\n","    out_data_dict = {}\n","    for name, tensor in data_dict.items():\n","        out_data_dict[name] = data_dict[name].to(device)\n","    yield out_data_dict"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMPeoqpOf7p3"},"source":["###The Model"]},{"cell_type":"code","metadata":{"id":"3GJCeb23f7wa","executionInfo":{"status":"ok","timestamp":1618250963059,"user_tz":-180,"elapsed":7033,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalClassifier(nn.Module):\n","  \"\"\" greek-Bert model with an extra linear layer, which takes \n","      the cls tocken as input, for classification \"\"\"\n","  def __init__(self, no_classes):\n","    \"\"\"\n","    Args:\n","        no_classes (int): the size of the linear layer\n","    \"\"\"\n","    super(LegalClassifier, self).__init__()\n","    print(\"Loading greek-Bert...\")\n","    self.bert = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","    self.dropout = nn.Dropout(0.1)\n","    self.fc = nn.Linear(768,no_classes)\n","    # for param in self.bert.parameters():\n","    #   param.requires_grad = False\n","\n","  def forward(self, input, mask, apply_softmax=False):\n","    \"\"\"The forward pass of the classifier\n","    Args:\n","        input (torch.Tensor): an input data tensor.\n","        mask (torch.Tensor): the coresponding masks for BERT\n","        apply_softmax (bool): whether or not to apply soflmax to the output layer\n","    Returns:\n","        the resulting tensor. tensor.shape should be (batch, output_dim)\n","    \"\"\"\n","    output = self.bert(input_ids=input, attention_mask=mask, \n","                       output_attentions=False, output_hidden_states=False)\n","    x = output.pooler_output # coresponds to CLS token\n","    x = self.dropout(x) \n","    x = self.fc(x)\n","    if apply_softmax:\n","        x = F.softmax(x, dim=1)\n","    return x"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oujVuInLieHc"},"source":["###helper functions"]},{"cell_type":"code","metadata":{"id":"wEbV1KG-ieOs","executionInfo":{"status":"ok","timestamp":1618250963059,"user_tz":-180,"elapsed":7025,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def make_train_state(args):\n","  return {'stop_early': False,\n","          'early_stopping_step': 0,\n","          'early_stopping_best_val': 1e8,\n","          'learning_rate': args.learning_rate,\n","          'epoch_index': 0,\n","          'train_loss': [],\n","          'train_acc': [],\n","          'val_loss': [],\n","          'val_acc': [],\n","          'test_loss': -1,\n","          'test_acc': -1,\n","          'model_filename': args.model_state_file}\n","\n","def update_train_state(args, model, train_state):\n","  \"\"\"Handle the training state updates.\n","\n","  Components:\n","    - Early Stopping: Prevent overfitting.\n","    - Model Checkpoint: Model is saved if the model is better\n","\n","  :param args: main arguments\n","  :param model: model to train\n","  :param train_state: a dictionary representing the training state values\n","  :returns:\n","      a new train_state\n","  \"\"\"\n","  # Save one model at least\n","  if train_state['epoch_index'] == 0:\n","    torch.save(model.state_dict(), train_state['model_filename'])\n","    train_state['stop_early'] = False\n","\n","  # Save model if performance improved\n","  elif train_state['epoch_index'] >= 1:\n","    loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","    # If loss worsened\n","    if loss_t >= train_state['early_stopping_best_val']:\n","      # Update step\n","      train_state['early_stopping_step'] += 1\n","    # Loss decreased\n","    else:\n","      # Save the best model\n","      if loss_t < train_state['early_stopping_best_val']:\n","          torch.save(model.state_dict(), train_state['model_filename'])\n","      # Reset early stopping step\n","      train_state['early_stopping_step'] = 0\n","\n","    # Stop early ?\n","    train_state['stop_early'] = \\\n","        train_state['early_stopping_step'] >= args.early_stopping_criteria\n","  return train_state\n","\n","def compute_accuracy(y_pred, y_target):\n","  _, y_pred_indices = y_pred.max(dim=1)\n","  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","  return n_correct / len(y_pred_indices) * 100"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ig-lwAAkh0w"},"source":["###Initializations"]},{"cell_type":"code","metadata":{"id":"zhbuS8_ZkiE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618250979659,"user_tz":-180,"elapsed":23619,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"8ef288b2-fab4-41a3-f21e-046b63f10292"},"source":["if args.expand_filepaths_to_save_dir:\n","  args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n","  args.reload_name = os.path.join(args.save_dir, args.reload_name)\n","  print(\"Expanded filepaths: \")\n","  print(\"\\t{}\".format(args.model_state_file))\n","  print(\"\\t{}\".format(args.reload_name))\n","\n","# Set seed for reproducibility\n","set_seed_everywhere(args.seed, args.cuda)\n","\n","# handle dirs\n","# handle_dirs(args.save_dir)\n","\n","dataset = LegalDataset()\n","vectorizer = dataset.get_vectorizer()\n","classifier = LegalClassifier(no_classes=args.no_classes)\n","\n","if args.reload_from_files:\n","    # training from a checkpoint\n","    print(\"Reloading previous model!\")\n","    classifier.load_state_dict(torch.load(args.reload_name))\n","else:\n","    print(\"Creating fresh!\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Expanded filepaths: \n","\t/content/drive/MyDrive/thesis/models/greek-BERT/model_chapter_8.pth\n","\t/content/drive/MyDrive/thesis/models/greek-BERT/model_chapter_8.pth\n","loading validation set...\n","loading training set...\n","loading test set...\n","Processing dataset...\n","Loading BERT tokenizer...\n","Calculating frequences...\n","Loading greek-Bert...\n","Reloading previous model!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f1h5wBjHw_Gs"},"source":["###Training Loop"]},{"cell_type":"code","metadata":{"id":"lMdq50aOw_Mr","executionInfo":{"status":"ok","timestamp":1618250979660,"user_tz":-180,"elapsed":23617,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["if args.run_training:\n","  classifier = classifier.to(args.device)\n","  # dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","  loss_func = nn.CrossEntropyLoss()#weight=dataset.class_weights)\n","  optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n","                                                  mode='min', factor=0.5, patience=1)\n","\n","  train_state = make_train_state(args)\n","\n","  epoch_bar = tqdm(desc='training routine', \n","                            total=args.num_epochs,\n","                            position=0)\n","\n","  dataset.set_split('train')\n","  train_bar = tqdm(desc='split=train',\n","                            total=dataset.get_num_batches(args.batch_size), \n","                            position=1, \n","                            leave=True)\n","  dataset.set_split('val')\n","  val_bar = tqdm(desc='split=val',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","  try:\n","    for epoch_index in range(args.num_epochs):\n","      train_state['epoch_index'] = epoch_index\n","\n","      # Iterate over training dataset\n","\n","      # setup: batch generator, set loss and acc to 0, set train mode on\n","\n","      dataset.set_split('train')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.0\n","      running_acc = 0.0\n","      classifier.train()\n","\n","      for batch_index, batch_dict in enumerate(batch_generator):\n","        # the training routine is these 5 steps:\n","\n","        # --------------------------------------\n","        # step 1. zero the gradients\n","        optimizer.zero_grad()\n","        # step 2. compute the output\n","        y_pred = classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","        # step 3. compute the loss\n","        loss = loss_func(y_pred, batch_dict['target'])\n","        loss_t = loss.item()\n","        running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","        # step 4. use loss to produce gradients\n","        loss.backward()\n","\n","        # step 5. use optimizer to take gradient step\n","        optimizer.step()\n","        # -----------------------------------------\n","        # compute the accuracy\n","        acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","        running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","        # update bar\n","        train_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                        epoch=epoch_index)\n","        train_bar.update()\n","\n","      train_state['train_loss'].append(running_loss)\n","      train_state['train_acc'].append(running_acc)\n","\n","      # Iterate over val dataset\n","\n","      # setup: batch generator, set loss and acc to 0; set eval mode on\n","      dataset.set_split('val')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.\n","      running_acc = 0.\n","      classifier.eval()\n","      with torch.no_grad():\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","          # compute the output\n","          y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","\n","          # compute the loss\n","          loss = loss_func(y_pred, batch_dict['target'])\n","          loss_t = loss.to(\"cpu\").item()\n","          running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","          # compute the accuracy\n","          acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","          running_acc += (acc_t - running_acc) / (batch_index + 1)\n","          val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                          epoch=epoch_index)\n","          \n","          val_bar.update()\n","\n","      train_state['val_loss'].append(running_loss)\n","      train_state['val_acc'].append(running_acc)\n","\n","      train_state = update_train_state(args=args, model=classifier,\n","                                        train_state=train_state)\n","\n","      scheduler.step(train_state['val_loss'][-1])\n","\n","      if train_state['stop_early']:\n","        break\n","\n","      train_bar.n = 0\n","      val_bar.n = 0\n","      epoch_bar.update()\n","  except KeyboardInterrupt:\n","      print(\"Exiting loop\")"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOXfsB2Y69Bd"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"2ENl_kjXBEki","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["4078bdfcc660446fb50e216a07771a2c","2041f8b0d8184243814a46320b6dc52e","72da06141da94c819cc3b112d5182cc3","103c13f46af44ee790e8c90b69ba7170","3c1cabe5f74543d3b483c22da4fde018","8156bc91118e437aa1e7c85d54e67abe","f15d5f6cd780406eaacaacfdf2fed79d","7f9d12e1c34748ed8a9caa013e8f8676"]},"executionInfo":{"status":"ok","timestamp":1618251325917,"user_tz":-180,"elapsed":369868,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"75322ffd-fde3-41e4-970e-1847f5c25f47"},"source":["# run test set and save results\n","\n","preds = []\n","correct = []\n","\n","classifier.load_state_dict(torch.load(args.model_state_file))\n","classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","\n","test_bar = tqdm(desc='split=test',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","classifier.eval()\n","with torch.no_grad():\n","  for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute output\n","    y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","    #save output\n","    preds += y_pred\n","    correct += batch_dict['target']\n","    test_bar.update()\n","\n","predictions = {'predictions' : preds,\n","              'correct' : correct}"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4078bdfcc660446fb50e216a07771a2c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=test', max=1189.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"aKIwkAS6UK1H","colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["95afca66e6954ae39d96c27465cad075","ff54fcdcc2344e789c14bd1858c6d7c0","716f44373fa3423695baee9e3c972771","04af7c9fe0ad46f0a632b2a57264b08c","95a26540c92d4f42a5edca20d51d5913","b520efca941846b589cc3f931ab61677","21ad18ab1601494db6a2e7eba64988d3","285817da7f94499db08bac4900725d32"]},"executionInfo":{"status":"ok","timestamp":1618251344700,"user_tz":-180,"elapsed":388635,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"4a0c2499-1c51-49cc-f8eb-d6d799eea810"},"source":["# tensors to cpu and find predicted class\n","tmp = []\n","for item in tqdm(predictions['predictions'], desc='predictions to cpu'):\n","  item = item.cpu()\n","  tmp.append(item.tolist().index(max(item)))\n","predictions['predictions'] = tmp\n","predictions['correct'] = torch.tensor(predictions['correct'], device = 'cpu').tolist()\n","\n","frequent = {'predictions' : [],\n","            'correct' : []}\n","few_shot = {'predictions' : [],\n","            'correct' : []}\n","\n","for pred, target in zip(predictions['predictions'], predictions['correct']):\n","  if dataset.class_counts[target] < 10 and dataset.class_counts[target] != 0:\n","    few_shot['predictions'].append(pred)\n","    few_shot['correct'].append(target)\n","  elif dataset.class_counts[target] > 10:\n","    frequent['predictions'].append(pred)\n","    frequent['correct'].append(target)\n","\n","for group, dict_ in zip(['All     \\t','Frequent\\t','Fewshot \\t'], [predictions, frequent, few_shot]):\n","  if 'All' in group:\n","    l = list(set(dict_['correct']) | set(dict_['predictions']))\n","  else:\n","    l = list(set(dict_['correct']))\n","  f1 = round(f1_score(dict_['correct'], dict_['predictions'], average='micro', labels=l)*100,2)\n","  rec = round(recall_score(dict_['correct'], dict_['predictions'], average='micro', labels=l)*100,2)\n","  prec = round(precision_score(dict_['correct'], dict_['predictions'], average='micro', labels=l)*100,2)\n","  print(group+'\\t f1: '+str(f1)+'\\t recall: '+str(rec)+'\\t precision: '+str(prec))"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95afca66e6954ae39d96c27465cad075","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='predictions to cpu', max=9512.0, style=ProgressStyle(desc…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","All     \t\t f1: 83.27\t recall: 83.27\t precision: 83.27\n","Frequent\t\t f1: 83.68\t recall: 83.61\t precision: 83.75\n","Fewshot \t\t f1: 68.49\t recall: 52.63\t precision: 98.04\n"],"name":"stdout"}]}]}