{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Greek_bert.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPGlGAalqtrJ6w/Ls8SLZY2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"80cf4a7dc87144f09b5f2e2a3ac1277f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5b8b3728f371498ca8bdb2ff8f73b5a9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a3461263ea284e9090cb35a40b3699e4","IPY_MODEL_22526c7f7935421fab2a248b2feb1ccc"]}},"5b8b3728f371498ca8bdb2ff8f73b5a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3461263ea284e9090cb35a40b3699e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_91a34f79cffe4bbc9ea452d1aa163ec4","_dom_classes":[],"description":"training routine: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc11b2cdf4fe46e99aa7bd502fda07e0"}},"22526c7f7935421fab2a248b2feb1ccc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_494766eb9d6c434f966ada95fe4143fd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [57:07&lt;00:00, 3427.63s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_48828609a10b404a8c1aca10ea093427"}},"91a34f79cffe4bbc9ea452d1aa163ec4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc11b2cdf4fe46e99aa7bd502fda07e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"494766eb9d6c434f966ada95fe4143fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"48828609a10b404a8c1aca10ea093427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0713d5010dd4ade9c6386b7ad822a20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_38f9ccda40a4432e9b503ea5dca7fef5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_600c2793feeb4cafbbe297aaed5d5da2","IPY_MODEL_56e629748d724e3fb60b6dd4f387f7cf"]}},"38f9ccda40a4432e9b503ea5dca7fef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"600c2793feeb4cafbbe297aaed5d5da2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e5c17568b9ca4d89a40ce2715fcd2e18","_dom_classes":[],"description":"split=train: 100%","_model_name":"FloatProgressModel","bar_style":"","max":3567,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3567,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ac26b5ad2c6453fbba6843498311c7b"}},"56e629748d724e3fb60b6dd4f387f7cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c2088751a144df393aaa92a4697fb98","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3567/3567 [50:48&lt;00:00,  1.17it/s, acc=95.9, epoch=0, loss=0.155]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_473800e946b94b6d95213afe37b975ec"}},"e5c17568b9ca4d89a40ce2715fcd2e18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0ac26b5ad2c6453fbba6843498311c7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c2088751a144df393aaa92a4697fb98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"473800e946b94b6d95213afe37b975ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f94b537a92cb438189df0814422fb2eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_848a18a3406942cdab65e0f142b087a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_371dba1a81ae4c8ab66bf9b710b8c66d","IPY_MODEL_db3fb29664c5424d851a9e72feb0b8f5"]}},"848a18a3406942cdab65e0f142b087a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"371dba1a81ae4c8ab66bf9b710b8c66d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c2f1e163324747f7a74c2573ced41e38","_dom_classes":[],"description":"split=val: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1188,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1188,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4dc37b7516904ecc96b18eb24eca9f21"}},"db3fb29664c5424d851a9e72feb0b8f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b49fc3873d944dda91cdaa67131b06c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1188/1188 [57:07&lt;00:00,  3.15it/s, acc=86.8, epoch=0, loss=0.605]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0337b5002325413ab64b70d0e6af24ce"}},"c2f1e163324747f7a74c2573ced41e38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4dc37b7516904ecc96b18eb24eca9f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b49fc3873d944dda91cdaa67131b06c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0337b5002325413ab64b70d0e6af24ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EEDBycDQOHOY","executionInfo":{"status":"ok","timestamp":1616795978654,"user_tz":-120,"elapsed":577,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["from argparse import Namespace\n","args = Namespace(\n","  # Data and path information\n","  dataset_path=\"/content/drive/MyDrive/thesis/dataset/\",\n","  model_state_file=\"model2.pth\",\n","  save_dir=\"/content/drive/MyDrive/thesis/\",\n","  # Training hyper parameters\n","  seed=1337,\n","  num_epochs=1,\n","  early_stopping_criteria=100,\n","  learning_rate=0.00001,\n","  batch_size=8,\n","  # Runtime options\n","  cuda=True,\n","  reload_from_files=False,\n","  expand_filepaths_to_save_dir=True,\n",")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uHTL519iZVZ"},"source":["###tmp"]},{"cell_type":"code","metadata":{"id":"9N1VlTthMldd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616795979233,"user_tz":-120,"elapsed":1146,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"801243ab-84ea-467a-80cc-c1096f711dd0"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive') "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rqkz0Hg1O2Up","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616795984390,"user_tz":-120,"elapsed":6291,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"abede7d8-fbce-4d3b-bca3-a76be36c5be1"},"source":["# from collections import Counter\n","\n","# import string\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","# https://torchmetrics.readthedocs.io/en/latest/index.html\n","!pip install torchmetrics\n","from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1\n","\n","# reading json files\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","\n","# huggingface lib bert\n","print('Loading transformers lib...')\n","!pip install transformers\n","from transformers import AutoTokenizer, AutoModel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.8.0+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\n","Loading transformers lib...\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VlFvFQUvOAcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616795984391,"user_tz":-120,"elapsed":6284,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"a61a8fda-9416-42b1-c03c-565ce3cc0a66"},"source":["# Check CUDA and gpu available\n","if not torch.cuda.is_available():\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Using CUDA: {}\".format(args.cuda))\n","if args.cuda:\n","  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using CUDA: True\n","GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EsVjpIsZKA4d"},"source":["###Transform dataset\n","transform json files to dataframes and save them as pickles"]},{"cell_type":"code","metadata":{"id":"8c0Ro4GK7WsL","executionInfo":{"status":"ok","timestamp":1616795984394,"user_tz":-120,"elapsed":6280,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# original_dataset_path = \"/content/drive/MyDrive/RAPTARCHIS47k/\"\n","\n","# def transform_save_data(path):\n","#   \"\"\"\n","#     transforms jason original dataset to dataframe and saves it to pickle \n","#   \"\"\"\n","#   df = pd.DataFrame(columns = column_names)\n","  \n","#   path1 = join(original_dataset_path,path)\n","#   bar = tqdm(desc=path, total=len(listdir(path1)), \n","#               position=1, leave=True)\n","  \n","#   for f in listdir(path1):\n","#     path2 = join(path1, f)\n","#     if isfile(path2):\n","#       with open(path2) as json_file:\n","#         data = json.load(json_file)\n","#         tmp = pd.Series([data['title'], data['type'], data['year'], \n","#                     data['law_id'] if data['law_id'] is not None else \"None\",\n","#                     data['leg_uri'] if data['leg_uri'] is not None else \"None\",\n","#                   data['volume'], data['chapter'], data['subject'], data['header'],\n","#                   data['header']], index = column_names)\n","#         df = df.append(tmp, ignore_index=True)\n","#         bar.update()\n","#   df.to_pickle(join(args.save_dir,'dataset/',path+'.pkl'))\n","\n","\n","# column_names=['title', 'type', 'year', 'law_id', 'leg_uri', \n","#               'volume', 'chapter', 'subject', 'header', 'articles']\n","# train_df = pd.DataFrame(columns = column_names)\n","# val_df = pd.DataFrame(columns = column_names)\n","# test_df = pd.DataFrame(columns = column_names)\n","\n","# transform_save_data('test')\n","# transform_save_data('dev')\n","# transform_save_data('train')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUbFqZMTYFOy"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"x5SVi3W8YFUb","executionInfo":{"status":"ok","timestamp":1616795984396,"user_tz":-120,"elapsed":6271,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def set_seed_everywhere(seed, cuda):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  # random.seed(seed)\n","  # !!!! may need to add hugingface init seed\n","  if cuda:\n","    torch.cuda.manual_seed_all(seed)\n","\n","def handle_dirs(dirpath):\n","  if not os.path.exists(dirpath):\n","    os.makedirs(dirpath)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A89dNcfGViGB"},"source":["### The Vectorizer"]},{"cell_type":"code","metadata":{"id":"8jG3SJWzViOn","executionInfo":{"status":"ok","timestamp":1616795984396,"user_tz":-120,"elapsed":6266,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalVectorizer(object):\n","  \"\"\" The Vectorizer\"\"\"\n","  def __init__(self, max_len=0):\n","    \"\"\"\n","    Args:\n","        LegalVectorizer (max_len): maps characters to integers and pads to max_len\n","    \"\"\"\n","    print('Loading BERT tokenizer...')\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\", model_max_length=512)\n","    self.max_len = max_len\n","\n","  def vectorize(self, text):\n","    \"\"\"\n","    Args:\n","        text (list of str):\n","    Returns:\n","        dictionary: \"vector\" is a tensor with a list of encoded text paded to max_len, ready for import to BERT\n","                    \"mask\" is a tensor with a list of masks ready for import to BERT\n","    \"\"\"\n","    encoded_dict = self.tokenizer(\n","                    text,                      # Sentence to encode.\n","                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                    # padding = 'longest', # pad to longest in bach\n","                    truncation = True, # truncates sentenses to 512, max bert length\n","                    padding = 'max_length',\n","                    # max_length = 512,           # Pad\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',     # Return pytorch tensors.\n","                )\n","\n","    return {\"vector\" : encoded_dict['input_ids'],\n","            \"mask\" : encoded_dict['attention_mask']}\n","\n","  def to_words(self, vector, remove_pads=True):\n","    \"\"\"\n","    Args:\n","        vector (tensor): list of vectors to decode\n","        remove_pads : remove pad \n","    Returns:\n","        list of lists of words coresponding to the vector values\n","    \"\"\"\n","    if remove_pads:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v[v.nonzero()]) for v in vector]\n","    else:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v) for v in vector]\n","    return ans\n","      "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNJNFcFXZItO","executionInfo":{"status":"ok","timestamp":1616795984397,"user_tz":-120,"elapsed":6250,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# vec=LegalVectorizer(20)\n","# batch_sentences = [\"δεν ξερω αμα δουλευει\",\n","#                    \"και\"]\n","# a=vec.vectorize(batch_sentences)\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CL6zGRvng0cb"},"source":["###The dataset"]},{"cell_type":"code","metadata":{"id":"9OVA8YQTg0QD","executionInfo":{"status":"ok","timestamp":1616795984398,"user_tz":-120,"elapsed":6246,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalDataset(Dataset):\n","  def __init__(self):\n","    \"\"\"\n","    Args:\n","    \"\"\"\n","\n","    print(\"loading validation set...\")\n","    self.val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","    self.validation_size = len(self.val_df)\n","\n","    class_names = self.val_df['volume'].unique()\n","    self.class_names = dict(zip(class_names, range(len(class_names))))\n","\n","    print(\"loading training set...\")\n","    self.train_df = pd.read_pickle(args.dataset_path + \"train.pkl\")\n","    self.train_size = len(self.train_df)\n","    print(\"loading test set...\")\n","    self.test_df = pd.read_pickle(args.dataset_path + \"test.pkl\")\n","    self.test_size = len(self.test_df)\n","    if self.val_df.shape[0]!=9511 or self.train_df.shape[0]!=28536 or self.test_df.shape[0]!=9516:\n","      print(self.val_df.shape[0])\n","      print(self.train_df.shape[0])\n","      print(self.test_df.shape[0])\n","      print(\"!! ERROR dataset size !!\")\n","      exit()\n","\n","    self.val_df['volume'] = self.val_df['volume'].replace(self.class_names)\n","    self.train_df['volume'] = self.train_df['volume'].replace(self.class_names)\n","    self.test_df['volume'] = self.test_df['volume'].replace(self.class_names)\n","\n","    self._vectorizer = LegalVectorizer()\n","    self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                          'val': (self.val_df, self.validation_size),\n","                          'test': (self.test_df, self.test_size)}\n","\n","    self.set_split('train')\n","    \n","    # Class weights\n","    # class_counts = df['target'].value_counts().to_dict()\n","    # print(class_counts)\n","    # def sort_key(item):\n","    #     return self._vectorizer.vocab.lookup_token(item[0])\n","    # sorted_counts = sorted(class_counts.items(), key=sort_key)\n","    # frequencies = [count for _, count in sorted_counts] ; \n","    # print(frequencies)\n","    # self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n","    # print(torch.tensor(frequencies, dtype=torch.float32))\n","    # print(self.class_weights)\n","\n","  def get_vectorizer(self):\n","      \"\"\" returns the vectorizer \"\"\"\n","      return self._vectorizer\n","\n","  def set_split(self, split):\n","      \"\"\" selects the splits in the dataset using _lookup_dict \"\"\"\n","      # self._target_split = split\n","      self._target_df, self._target_size = self._lookup_dict[split]\n","\n","  def __len__(self):\n","      return self._target_size\n","\n","  def __getitem__(self, index):\n","      \"\"\"the primary entry point method for PyTorch datasets\n","      Args:\n","          index (int): the index to the data point \n","      Returns:\n","          a dictionary holding the data point's:\n","              features (x_surname)\n","              label (y_nationality)\n","      \"\"\"\n","      row = self._target_df.iloc[index]\n","      # id =  row['law_id']\n","      volume = row['volume']\n","      # chapter = row['chapter']\n","      # subject = row['subject']\n","      # title type header ????\n","      tmp = self._vectorizer.vectorize(row['articles'])\n","      mask, vector = tmp['mask'], tmp['vector']\n","\n","      return {#'id': id,\n","              'volume': volume,\n","              #'chapter': chapter,\n","              #'subject': subject,\n","              'vector': vector,\n","              'mask' : mask}\n","\n","  def get_num_batches(self, batch_size):\n","      \"\"\"Given a batch size, return the number of batches in the dataset\n","      Args:\n","          batch_size (int)\n","      Returns:\n","          number of batches in the dataset\n","      \"\"\"\n","      return len(self) // batch_size"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBAMThqhdzPI","executionInfo":{"status":"ok","timestamp":1616795984398,"user_tz":-120,"elapsed":6239,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","# vec=LegalVectorizer(20)\n","# a=vec.vectorize(val_df['articles'][0])\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5SEw2hUfv5G"},"source":["###Dataloader"]},{"cell_type":"code","metadata":{"id":"-q4zXTEffv_V","executionInfo":{"status":"ok","timestamp":1616795984399,"user_tz":-120,"elapsed":6236,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"): \n","    \"\"\"\n","    A generator function which wraps the PyTorch DataLoader. It will \n","      ensure each tensor is on the write device location.\n","    \"\"\"\n","    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                            shuffle=shuffle, drop_last=drop_last)\n","\n","    for data_dict in dataloader:\n","        out_data_dict = {}\n","        for name, tensor in data_dict.items():\n","            out_data_dict[name] = data_dict[name].to(device)\n","        yield out_data_dict"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMPeoqpOf7p3"},"source":["###The Model"]},{"cell_type":"code","metadata":{"id":"3GJCeb23f7wa","executionInfo":{"status":"ok","timestamp":1616795984399,"user_tz":-120,"elapsed":6229,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalClassifier(nn.Module):\n","  \"\"\" greek-Bert model with an extra linear layer, which takes \n","      the cls tocken as input, for classification \"\"\"\n","  def __init__(self, no_classes):\n","    \"\"\"\n","    Args:\n","        no_classes (int): the size of the linear layer\n","    \"\"\"\n","    super(LegalClassifier, self).__init__()\n","    print(\"Loading greek-Bert...\")\n","    self.bert = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","    self.dropout = nn.Dropout(0.1)\n","    self.fc = nn.Linear(768,no_classes)\n","    # for param in self.bert.parameters():\n","    #   param.requires_grad = False\n","\n","  def forward(self, input, mask, apply_softmax=False):\n","    \"\"\"The forward pass of the classifier\n","    Args:\n","        input (torch.Tensor): an input data tensor. \n","                shape should be (batch, input_dim)\n","        mask (torch.Tensor): the coresponding masks for BERT\n","    Returns:\n","        the resulting tensor. tensor.shape should be (batch, output_dim)\n","    \"\"\"\n","    output = self.bert(input_ids=input, attention_mask=mask, \n","                       output_attentions=False, output_hidden_states=False)\n","    x = output[0][:,0,:] # [0][0] coresponds to CLS token\n","    x = self.dropout(x) \n","    x = self.fc(x)\n","    if apply_softmax:\n","        x = F.softmax(x, dim=1)\n","    return x"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oujVuInLieHc"},"source":["###helper functions"]},{"cell_type":"code","metadata":{"id":"wEbV1KG-ieOs","executionInfo":{"status":"ok","timestamp":1616795984706,"user_tz":-120,"elapsed":6532,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def make_train_state(args):\n","  return {'stop_early': False,\n","          'early_stopping_step': 0,\n","          'early_stopping_best_val': 1e8,\n","          'learning_rate': args.learning_rate,\n","          'epoch_index': 0,\n","          'train_loss': [],\n","          'train_acc': [],\n","          'val_loss': [],\n","          'val_acc': [],\n","          'test_loss': -1,\n","          'test_acc': -1,\n","          'model_filename': args.model_state_file}\n","\n","def update_train_state(args, model, train_state):\n","  \"\"\"Handle the training state updates.\n","\n","  Components:\n","    - Early Stopping: Prevent overfitting.\n","    - Model Checkpoint: Model is saved if the model is better\n","\n","  :param args: main arguments\n","  :param model: model to train\n","  :param train_state: a dictionary representing the training state values\n","  :returns:\n","      a new train_state\n","  \"\"\"\n","\n","  # Save one model at least\n","  if train_state['epoch_index'] == 0:\n","    torch.save(model.state_dict(), train_state['model_filename'])\n","    train_state['stop_early'] = False\n","\n","  # Save model if performance improved\n","  elif train_state['epoch_index'] >= 1:\n","    loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","    # If loss worsened\n","    if loss_t >= train_state['early_stopping_best_val']:\n","      # Update step\n","      train_state['early_stopping_step'] += 1\n","    # Loss decreased\n","    else:\n","      # Save the best model\n","      if loss_t < train_state['early_stopping_best_val']:\n","          torch.save(model.state_dict(), train_state['model_filename'])\n","      # Reset early stopping step\n","      train_state['early_stopping_step'] = 0\n","\n","    # Stop early ?\n","    train_state['stop_early'] = \\\n","        train_state['early_stopping_step'] >= args.early_stopping_criteria\n","\n","  return train_state\n","\n","def compute_accuracy(y_pred, y_target):\n","  _, y_pred_indices = y_pred.max(dim=1)\n","  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","  return n_correct / len(y_pred_indices) * 100"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ig-lwAAkh0w"},"source":["###Initializations"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhbuS8_ZkiE4","executionInfo":{"status":"ok","timestamp":1616795991535,"user_tz":-120,"elapsed":13355,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"ff27f42b-080f-4406-ef30-a3710ab2a356"},"source":["if args.expand_filepaths_to_save_dir:\n","  args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n","  print(\"Expanded filepaths: \")\n","  # print(\"\\t{}\".format(args.vectorizer_file))\n","  print(\"\\t{}\".format(args.model_state_file))\n","\n","# Set seed for reproducibility\n","set_seed_everywhere(args.seed, args.cuda)\n","\n","# handle dirs\n","# handle_dirs(args.save_dir)\n","\n","if args.reload_from_files:\n","    # training from a checkpoint\n","    print(\"Reloading!\")\n","    dataset = TweetDataset.load_dataset_and_load_vectorizer(args.tweet_csv, args.vectorizer_file)\n","else:\n","    # create dataset and vectorizer\n","    print(\"Creating fresh!\")\n","    dataset = LegalDataset()\n","    # dataset.save_vectorizer(args.vectorizer_file)\n","    \n","vectorizer = dataset.get_vectorizer()\n","classifier = LegalClassifier(no_classes=47)\n","classifier.load_state_dict(torch.load(args.model_state_file))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Expanded filepaths: \n","\t/content/drive/MyDrive/thesis/model2.pth\n","Creating fresh!\n","loading validation set...\n","loading training set...\n","loading test set...\n","Loading BERT tokenizer...\n","Loading greek-Bert...\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"f1h5wBjHw_Gs"},"source":["###Training Loop"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["80cf4a7dc87144f09b5f2e2a3ac1277f","5b8b3728f371498ca8bdb2ff8f73b5a9","a3461263ea284e9090cb35a40b3699e4","22526c7f7935421fab2a248b2feb1ccc","91a34f79cffe4bbc9ea452d1aa163ec4","bc11b2cdf4fe46e99aa7bd502fda07e0","494766eb9d6c434f966ada95fe4143fd","48828609a10b404a8c1aca10ea093427","e0713d5010dd4ade9c6386b7ad822a20","38f9ccda40a4432e9b503ea5dca7fef5","600c2793feeb4cafbbe297aaed5d5da2","56e629748d724e3fb60b6dd4f387f7cf","e5c17568b9ca4d89a40ce2715fcd2e18","0ac26b5ad2c6453fbba6843498311c7b","2c2088751a144df393aaa92a4697fb98","473800e946b94b6d95213afe37b975ec","f94b537a92cb438189df0814422fb2eb","848a18a3406942cdab65e0f142b087a7","371dba1a81ae4c8ab66bf9b710b8c66d","db3fb29664c5424d851a9e72feb0b8f5","c2f1e163324747f7a74c2573ced41e38","4dc37b7516904ecc96b18eb24eca9f21","2b49fc3873d944dda91cdaa67131b06c","0337b5002325413ab64b70d0e6af24ce"]},"id":"lMdq50aOw_Mr","executionInfo":{"status":"ok","timestamp":1616799419498,"user_tz":-120,"elapsed":3441312,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"c953562e-89b2-4bc5-f5de-58e5b89d242f"},"source":["classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","loss_func = nn.CrossEntropyLoss()#dataset.class_weights)\n","optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n","                                                 mode='min', factor=0.5, patience=1) #adjusts learning rate\n","     #torch.optim.lr_scheduler provides several methods to adjust the learning rate based on \n","     #the number of epochs. torch.optim.lr_scheduler.ReduceLROnPlateau allows dynamic \n","     #learning rate reducing based on some validation measurements.\n","\n","train_state = make_train_state(args)\n","\n","epoch_bar = tqdm(desc='training routine', \n","                          total=args.num_epochs,\n","                          position=0)\n","\n","dataset.set_split('train')\n","train_bar = tqdm(desc='split=train',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","dataset.set_split('val')\n","val_bar = tqdm(desc='split=val',\n","                        total=dataset.get_num_batches(args.batch_size), \n","                        position=1, \n","                        leave=True)\n","\n","# metric_collection = MetricCollection([\n","#     Accuracy(),\n","#     Precision(num_classes=47, average='micro'),\n","#     Recall(num_classes=47, average='micro'),\n","#     F1(num_classes=47, average='micro')\n","# ]).to(args.device)\n","\n","try:\n","  for epoch_index in range(args.num_epochs):\n","    train_state['epoch_index'] = epoch_index\n","\n","    # Iterate over training dataset\n","\n","    # setup: batch generator, set loss and acc to 0, set train mode on\n","\n","    dataset.set_split('train')\n","    batch_generator = generate_batches(dataset, \n","                                        batch_size=args.batch_size, \n","                                        device=args.device)\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    classifier.train()\n","\n","    for batch_index, batch_dict in enumerate(batch_generator):\n","      # the training routine is these 5 steps:\n","\n","      # --------------------------------------\n","      # step 1. zero the gradients\n","      optimizer.zero_grad()\n","      # step 2. compute the output\n","      y_pred = classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","      # step 3. compute the loss\n","      loss = loss_func(y_pred, batch_dict['volume'])\n","      loss_t = loss.item()\n","      running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","      # step 4. use loss to produce gradients\n","      loss.backward()\n","\n","      # step 5. use optimizer to take gradient step\n","      optimizer.step()\n","      # -----------------------------------------\n","      # compute the accuracy\n","      acc_t = compute_accuracy(y_pred, batch_dict['volume'])\n","      running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","      # update bar\n","      train_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                      epoch=epoch_index)\n","      train_bar.update()\n","\n","    train_state['train_loss'].append(running_loss)\n","    train_state['train_acc'].append(running_acc)\n","\n","    # Iterate over val dataset\n","\n","    # setup: batch generator, set loss and acc to 0; set eval mode on\n","    dataset.set_split('val')\n","    batch_generator = generate_batches(dataset, \n","                                        batch_size=args.batch_size, \n","                                        device=args.device)\n","    running_loss = 0.\n","    running_acc = 0.\n","    classifier.eval()\n","\n","    for batch_index, batch_dict in enumerate(batch_generator):\n","      # compute the output\n","      y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","\n","      # compute the loss\n","      loss = loss_func(y_pred, batch_dict['volume'])\n","      loss_t = loss.to(\"cpu\").item()\n","      running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","      # compute the accuracy\n","      acc_t = compute_accuracy(y_pred, batch_dict['volume'])\n","      running_acc += (acc_t - running_acc) / (batch_index + 1)\n","      val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                      epoch=epoch_index)\n","      \n","      # metric_collection.update(y_pred, batch_dict['volume'])\n","\n","      val_bar.update()\n","\n","    train_state['val_loss'].append(running_loss)\n","    train_state['val_acc'].append(running_acc)\n","    # metrics = metric_collection.compute()\n","    # print(metrics)\n","    # metric_collection.reset()\n","\n","\n","    train_state = update_train_state(args=args, model=classifier,\n","                                      train_state=train_state)\n","\n","    scheduler.step(train_state['val_loss'][-1])\n","\n","    # if train_state['stop_early']:\n","    #   break\n","\n","    train_bar.n = 0\n","    val_bar.n = 0\n","    epoch_bar.update()\n","except KeyboardInterrupt:\n","    print(\"Exiting loop\")"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80cf4a7dc87144f09b5f2e2a3ac1277f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', max=1.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0713d5010dd4ade9c6386b7ad822a20","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=3567.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f94b537a92cb438189df0814422fb2eb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=1188.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"DzRDHukTMn8T","executionInfo":{"status":"error","timestamp":1616799443307,"user_tz":-120,"elapsed":464,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"c6a32b08-2607-4967-91e1-f0998f05825a"},"source":["# compute the metrics on the test set using the best available model\n","\n","metric_collection = MetricCollection([\n","    Accuracy(),\n","    Precision(num_classes=47, average='micro'),\n","    Recall(num_classes=47, average='micro'),\n","    F1(num_classes=47, average='micro')\n","]).to(args.device)\n","\n","classifier.load_state_dict(torch.load(args.model_state_file))\n","\n","classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","loss_func = nn.CrossEntropyLoss()#dataset.class_weights)\n","\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","\n","test_bar = tqdm(desc='split=test',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","running_loss = 0.\n","running_acc = 0.\n","classifier.eval()\n","\n","for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute the output\n","    y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","    \n","    # # compute the loss\n","    # loss = loss_func(y_pred, batch_dict['volume'])\n","    # loss_t = loss.item()\n","    # running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","    # # compute the accuracy\n","    acc_t = compute_accuracy(y_pred, batch_dict['volume'])\n","    running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","    metric_collection.update(y_pred, batch_dict['volume'])\n","    test_bar.update()\n","metrics = metric_collection.compute()\n","print(metrics)\n","# train_state['test_loss'] = running_loss\n","# train_state['test_acc'] = running_acc\n","print(running_acc)"],"execution_count":17,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-78287d725118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m ]).to(args.device)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_state_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 14.76 GiB total capacity; 13.59 GiB already allocated; 35.75 MiB free; 13.69 GiB reserved in total by PyTorch)"]}]}]}