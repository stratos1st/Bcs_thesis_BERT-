{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Greek_bert.ipynb","provenance":[],"collapsed_sections":["4uHTL519iZVZ","EsVjpIsZKA4d","nUbFqZMTYFOy","A89dNcfGViGB","CL6zGRvng0cb","t5SEw2hUfv5G","gMPeoqpOf7p3"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3a7bfdd56d034a83b4cb6b08a7b1f084":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_19e5403526f9402dbc04260d2f1852af","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_78b81d3885614af7a93e88ee22202b8e","IPY_MODEL_78184c00aae0491392f52fc25d2a468e"]}},"19e5403526f9402dbc04260d2f1852af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78b81d3885614af7a93e88ee22202b8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4c4a250a9d994691ab110949705e2142","_dom_classes":[],"description":"training routine:   7%","_model_name":"FloatProgressModel","bar_style":"","max":15,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_106c6c26a21c4177b4d9e4eaa36e1e66"}},"78184c00aae0491392f52fc25d2a468e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c33324715634bebb3434a872deeeec7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/15 [03:59&lt;55:53, 239.54s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89fbffdd1eb0450c92ece74ee75d8f21"}},"4c4a250a9d994691ab110949705e2142":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"106c6c26a21c4177b4d9e4eaa36e1e66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c33324715634bebb3434a872deeeec7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89fbffdd1eb0450c92ece74ee75d8f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0b0fd731d66464c9914b356bf4c4b25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ebb5e793fb194afd93aba656b20dde70","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3c50adfdf9394c1ab871a56aac39dc7c","IPY_MODEL_214cb2adddb74e1fb14fe821a037e762"]}},"ebb5e793fb194afd93aba656b20dde70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c50adfdf9394c1ab871a56aac39dc7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5fd74b00842f45d49f3e675b7ea952d4","_dom_classes":[],"description":"split=train:  24%","_model_name":"FloatProgressModel","bar_style":"","max":445,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":107,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6414f05fc8e84915bef8aaf678625421"}},"214cb2adddb74e1fb14fe821a037e762":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b154a9a60d114cf981777e378b6a3b7f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 107/445 [04:51&lt;02:37,  2.15it/s, acc=99.2, epoch=1, loss=0.0636]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db42598ea88e4d55b592f397031cb4c8"}},"5fd74b00842f45d49f3e675b7ea952d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6414f05fc8e84915bef8aaf678625421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b154a9a60d114cf981777e378b6a3b7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db42598ea88e4d55b592f397031cb4c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b9435e6a026496c9b2b06b3e124739b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1493053b54d34697b8a1a0e3b1d2809c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_01e952edf0d046e584ba9ed5e2edcd17","IPY_MODEL_01bf44a410244c23ae30e20d721324d5"]}},"1493053b54d34697b8a1a0e3b1d2809c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01e952edf0d046e584ba9ed5e2edcd17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_304b9828a0284d1db45ed35150337280","_dom_classes":[],"description":"split=val: 100%","_model_name":"FloatProgressModel","bar_style":"","max":148,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":148,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a615c51c7a6249b785f0cae0a3a68973"}},"01bf44a410244c23ae30e20d721324d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0d7b0fb6dad492abec45600bb3d0947","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 148/148 [03:57&lt;00:00,  6.03it/s, acc=75.2, epoch=0, loss=1.37]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb3301682f224ec186fe5935b6e81619"}},"304b9828a0284d1db45ed35150337280":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a615c51c7a6249b785f0cae0a3a68973":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0d7b0fb6dad492abec45600bb3d0947":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eb3301682f224ec186fe5935b6e81619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"EEDBycDQOHOY","executionInfo":{"status":"ok","timestamp":1617307724578,"user_tz":-180,"elapsed":824,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["from argparse import Namespace\n","args = Namespace(\n","  # Data and path information\n","  dataset_path=\"/content/drive/MyDrive/thesis/dataset/\",\n","  model_state_file=\"model_chapter_test\",\n","  save_dir=\"/content/drive/MyDrive/thesis/\",\n","  no_classes = 389, # 2285, 389, 47\n","  class_name = 'chapter',\n","  # Training hyper parameters\n","  seed=1338,\n","  num_epochs=15,\n","  early_stopping_criteria=2,\n","  learning_rate=0.00002,\n","  batch_size=64,\n","  # Runtime options\n","  cuda=True,\n","  reload_from_files=True,\n","  reload_name=\"model_chapter_test_7.pth\",\n","  expand_filepaths_to_save_dir=True,\n",")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uHTL519iZVZ"},"source":["###tmp"]},{"cell_type":"code","metadata":{"id":"9N1VlTthMldd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617307724580,"user_tz":-180,"elapsed":817,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"77a1d11d-5921-4f37-d00e-0e66a63001c1"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive') "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rqkz0Hg1O2Up","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617307732599,"user_tz":-180,"elapsed":8831,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"bc20f909-9016-4f59-9e14-a79a7caab7c9"},"source":["# from collections import Counter\n","\n","# import string\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","!pip install torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","print('Loading torchmetrics lib...')\n","# https://torchmetrics.readthedocs.io/en/latest/index.html\n","!pip install torchmetrics\n","from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1\n","\n","# reading json files\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","\n","# huggingface lib bert\n","print('Loading transformers lib...')\n","!pip install transformers\n","from transformers import AutoTokenizer, AutoModel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Loading torchmetrics lib...\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n","Loading transformers lib...\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VlFvFQUvOAcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617307732610,"user_tz":-180,"elapsed":8835,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"4f81d225-332b-4518-8d77-fa1d6f053f1c"},"source":["# Check CUDA and gpu available\n","if not torch.cuda.is_available():\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Using CUDA: {}\".format(args.cuda))\n","if args.cuda:\n","  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using CUDA: True\n","GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EsVjpIsZKA4d"},"source":["###Transform dataset\n","transform json files to dataframes and save them as pickles"]},{"cell_type":"code","metadata":{"id":"8c0Ro4GK7WsL","executionInfo":{"status":"ok","timestamp":1617307732612,"user_tz":-180,"elapsed":8831,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# # computed in local runtime\n","# # original_dataset_path = \"/content/drive/MyDrive/RAPTARCHIS47k\"\n","# original_dataset_path = \"/mnt/D21005A6100592A1/ΕΚΠΑ/πτυχιακή/Bert-final/\"\n","# column_names=['title', 'type', 'year', 'law_id', 'leg_uri','volume', \n","#               'chapter', 'subject', 'header', 'articles']\n","\n","# def transform_save_data(path):\n","#   \"\"\"\n","#     transforms jason original dataset to dataframe and saves it to pickle \n","#   \"\"\"\n","#   df = pd.DataFrame(columns = column_names)\n","  \n","#   path1 = join(original_dataset_path,path)\n","#   bar = tqdm(desc=path, total=len(listdir(path1)), \n","#               position=1, leave=True)\n","\n","#   articles = []\n","#   for f in listdir(path1):\n","#     path2 = join(path1, f)\n","#     if isfile(path2):\n","#       with open(path2) as json_file:\n","#         data = json.load(json_file)\n","#         # json to dataframe\n","                    \n","#         tmp = pd.Series([data['title'], data['type'], data['year'], \n","#                     data['law_id'] if data['law_id'] is not None else \"None\",\n","#                     data['leg_uri'] if data['leg_uri'] is not None else \"None\",\n","#                     data['volume'], data['chapter'], data['subject'], \n","#                     data['header'],\"\"], index = column_names)\n","#         df = df.append(tmp, ignore_index=True)\n","#         # process articles list\n","#         tmp2 = \"\"\n","#         for i in data['articles']:\n","#           tmp2 += i + \" \"\n","#         articles.append(tmp2)\n","#         bar.update()\n","#   df['articles'] = articles\n","#   # df.to_pickle(join(args.save_dir,'dataset/',path+'.pkl'))\n","#   df.to_pickle(original_dataset_path+path+'.pkl')\n","\n","# train_df = pd.DataFrame(columns = column_names)\n","# val_df = pd.DataFrame(columns = column_names)\n","# test_df = pd.DataFrame(columns = column_names)\n","\n","# transform_save_data('test')\n","# transform_save_data('dev')\n","# transform_save_data('train')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUbFqZMTYFOy"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"x5SVi3W8YFUb","executionInfo":{"status":"ok","timestamp":1617307732613,"user_tz":-180,"elapsed":8827,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def set_seed_everywhere(seed, cuda):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  # random.seed(seed)\n","  # !!!! may need to add hugingface init seed\n","  if cuda:\n","    torch.cuda.manual_seed_all(seed)\n","\n","def handle_dirs(dirpath):\n","  if not os.path.exists(dirpath):\n","    os.makedirs(dirpath)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A89dNcfGViGB"},"source":["### The Vectorizer"]},{"cell_type":"code","metadata":{"id":"8jG3SJWzViOn","executionInfo":{"status":"ok","timestamp":1617307732614,"user_tz":-180,"elapsed":8822,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalVectorizer(object):\n","  \"\"\" The Vectorizer\"\"\"\n","  def __init__(self):\n","    \"\"\"\n","    Args:\n","        LegalVectorizer (max_len): maps characters to integers and pads to max_len\n","    \"\"\"\n","    print('Loading BERT tokenizer...')\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\", model_max_length=512)\n","\n","  def vectorize(self, text):\n","    \"\"\"\n","    Args:\n","        text (list of str):\n","    Returns:\n","        dictionary: \"vector\" is a tensor with a list of encoded text paded to max_len, ready for import to BERT\n","                    \"mask\" is a tensor with a list of masks ready for import to BERT\n","    \"\"\"\n","\n","    encoded_dict = self.tokenizer(\n","                    text,                      # Sentence to encode.\n","                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                    padding = True, # pad to longest in bach\n","                    truncation = True, # truncates sentenses to 512, max bert length\n","                    # padding = 'max_length',\n","                    # max_length = 512,           # Pad\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',     # Return pytorch tensors.\n","                )\n","\n","    return {\"vector\" : encoded_dict['input_ids'],\n","            \"mask\" : encoded_dict['attention_mask']}\n","  def get_pad_tocken(self):\n","    return self.tokenizer.pad_token_id\n","\n","  def to_words(self, vector, remove_pads=True):\n","    \"\"\"\n","    Args:\n","        vector (tensor): list of vectors to decode\n","        remove_pads : remove pad \n","    Returns:\n","        list of lists of words coresponding to the vector values\n","    \"\"\"\n","    if remove_pads:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v[v.nonzero()]) for v in vector]\n","    else:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v) for v in vector]\n","    return ans\n","      "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNJNFcFXZItO","executionInfo":{"status":"ok","timestamp":1617307732615,"user_tz":-180,"elapsed":8817,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# dataset = LegalDataset()\n","# vec=dataset.get_vectorizer()\n","# batch_sentences = [\"δεν ξερω αμα δουλευει\",\n","#                    \"και\"]\n","# a=vec.vectorize(batch_sentences)\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CL6zGRvng0cb"},"source":["###The dataset"]},{"cell_type":"code","metadata":{"id":"9OVA8YQTg0QD","executionInfo":{"status":"ok","timestamp":1617307732616,"user_tz":-180,"elapsed":8813,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalDataset(Dataset):\n","  def __init__(self):\n","    \"\"\"\n","    Args:\n","    \"\"\"\n","\n","    print(\"loading validation set...\")\n","    self.val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","    self.validation_size = len(self.val_df)\n","    print(\"loading training set...\")\n","    self.train_df = pd.read_pickle(args.dataset_path + \"train.pkl\")\n","    self.train_size = len(self.train_df)\n","    print(\"loading test set...\")\n","    self.test_df = pd.read_pickle(args.dataset_path + \"test.pkl\")\n","    self.test_size = len(self.test_df)\n","    # check the dataset size (dataset has extra files when aploaded to google drive. it mekes copies ex. \"123 (1).json\")\n","    if self.val_df.shape[0]!=9511 or self.train_df.shape[0]!=28536 or self.test_df.shape[0]!=9516:\n","      print(self.val_df.shape[0])\n","      print(self.train_df.shape[0])\n","      print(self.test_df.shape[0])\n","      print(\"!! ERROR dataset size !!\")\n","      exit()\n","\n","    print(\"Processing dataset...\")\n","    # replace class names with 0-n numbers\n","    class_names = pd.concat([ self.val_df[args.class_name],\n","                             self.train_df[args.class_name],\n","                             self.test_df[args.class_name] ]).unique()\n","    self.class_names = dict(zip(class_names, range(len(class_names))))\n","    self.val_df[args.class_name] = self.val_df[args.class_name].replace(self.class_names)\n","    self.train_df[args.class_name] = self.train_df[args.class_name].replace(self.class_names)\n","    self.test_df[args.class_name] = self.test_df[args.class_name].replace(self.class_names)\n","    # delete usless stuff\n","    self.val_df = self.val_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.train_df = self.train_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.test_df = self.test_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","\n","    self._vectorizer = LegalVectorizer()\n","    self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                          'val': (self.val_df, self.validation_size),\n","                          'test': (self.test_df, self.test_size)}\n","\n","    self.set_split('train')\n","\n","    print(\"Done\")\n","    # # Class weights\n","    # class_counts = []\n","    # for v in range(args.no_classes):\n","    #   tmp = self.train_df[self.train_df[args.class_name]==v][args.class_name].count()\n","    #   if tmp>0:\n","    #     class_counts.append(tmp)\n","    #   else:\n","    #     class_counts.append(1)\n","    # self.class_weights = 10000.0 / torch.tensor(class_counts, dtype=torch.float32)\n","\n","  def get_vectorizer(self):\n","    \"\"\" returns the vectorizer \"\"\"\n","    return self._vectorizer\n","\n","  def set_split(self, split):\n","    \"\"\" selects the splits in the dataset using _lookup_dict \"\"\"\n","    # self._target_split = split\n","    self._target_df, self._target_size = self._lookup_dict[split]\n","\n","  def __len__(self):\n","    return self._target_size\n","\n","  def __getitem__(self, index):\n","    \"\"\"the primary entry point method for PyTorch datasets\n","    Args:\n","        index (int): the index to the data point \n","    Returns:\n","        a dictionary holding the data point's\n","    \"\"\"\n","    row = self._target_df.iloc[index]\n","    # id =  row['law_id']\n","    target = row[args.class_name]\n","    # text = row['header'] + \" \"\n","    # text += row['articles']\n","    \n","    tmp = row['header'].split()[:30]\n","    text = \"\"\n","    for i in tmp:\n","      text += i + \" \"\n","\n","    return {#'id': id,\n","            'target': target,\n","            #'chapter': chapter,\n","            #'subject': subject,\n","            # 'vector': vector,\n","            # 'mask' : mask,\n","            'text' : text}\n","      \n","  def get_num_batches(self, batch_size):\n","    \"\"\"Given a batch size, return the number of batches in the dataset\n","    Args:\n","      batch_size (int)\n","    Returns:\n","      number of batches in the dataset\n","    \"\"\"\n","    return len(self) // batch_size"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBAMThqhdzPI","executionInfo":{"status":"ok","timestamp":1617307732617,"user_tz":-180,"elapsed":8810,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","# vec=LegalVectorizer(20)\n","# a=vec.vectorize(val_df['articles'][0])\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5SEw2hUfv5G"},"source":["###Dataloader"]},{"cell_type":"code","metadata":{"id":"-q4zXTEffv_V","executionInfo":{"status":"ok","timestamp":1617307732618,"user_tz":-180,"elapsed":8806,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# http://mccormickml.com/2020/07/29/smart-batching-tutorial\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"): \n","  \"\"\"\n","  A generator function which wraps the PyTorch DataLoader. It will \n","    ensure each tensor is on the write device location.\n","  \"\"\"\n","  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                          shuffle=shuffle, drop_last=drop_last)\n","\n","  for data_dict in dataloader:\n","    tmp = dataset.get_vectorizer().vectorize(data_dict['text'])\n","    mask, vector = tmp['mask'], tmp['vector']\n","    data_dict['vector'] = vector\n","    data_dict['mask'] = mask\n","    del data_dict['text']\n","\n","    out_data_dict = {}\n","    for name, tensor in data_dict.items():\n","        out_data_dict[name] = data_dict[name].to(device)\n","    yield out_data_dict"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMPeoqpOf7p3"},"source":["###The Model"]},{"cell_type":"code","metadata":{"id":"3GJCeb23f7wa","executionInfo":{"status":"ok","timestamp":1617307732618,"user_tz":-180,"elapsed":8802,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalClassifier(nn.Module):\n","  \"\"\" greek-Bert model with an extra linear layer, which takes \n","      the cls tocken as input, for classification \"\"\"\n","  def __init__(self, no_classes):\n","    \"\"\"\n","    Args:\n","        no_classes (int): the size of the linear layer\n","    \"\"\"\n","    super(LegalClassifier, self).__init__()\n","    print(\"Loading greek-Bert...\")\n","    self.bert = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","    self.dropout = nn.Dropout(0.1)\n","    self.fc = nn.Linear(768,no_classes)\n","    # for param in self.bert.parameters():\n","    #   param.requires_grad = False\n","\n","  def forward(self, input, mask, apply_softmax=False):\n","    \"\"\"The forward pass of the classifier\n","    Args:\n","        input (torch.Tensor): an input data tensor. \n","                shape should be (batch, input_dim)\n","        mask (torch.Tensor): the coresponding masks for BERT\n","    Returns:\n","        the resulting tensor. tensor.shape should be (batch, output_dim)\n","    \"\"\"\n","    output = self.bert(input_ids=input, attention_mask=mask, \n","                       output_attentions=False, output_hidden_states=False)\n","    x = output.pooler_output # coresponds to CLS token\n","    x = self.dropout(x) \n","    x = self.fc(x)\n","    if apply_softmax:\n","        x = F.softmax(x, dim=1)\n","    return x"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oujVuInLieHc"},"source":["###helper functions"]},{"cell_type":"code","metadata":{"id":"wEbV1KG-ieOs","executionInfo":{"status":"ok","timestamp":1617307732620,"user_tz":-180,"elapsed":8800,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def make_train_state(args):\n","  return {'stop_early': False,\n","          'early_stopping_step': 0,\n","          'early_stopping_best_val': 1e8,\n","          'learning_rate': args.learning_rate,\n","          'epoch_index': 0,\n","          'train_loss': [],\n","          'train_acc': [],\n","          'val_loss': [],\n","          'val_acc': [],\n","          'test_loss': -1,\n","          'test_acc': -1,\n","          'model_filename': args.model_state_file}\n","\n","def update_train_state(args, model, train_state):\n","  \"\"\"Handle the training state updates.\n","\n","  Components:\n","    - Early Stopping: Prevent overfitting.\n","    - Model Checkpoint: Model is saved if the model is better\n","\n","  :param args: main arguments\n","  :param model: model to train\n","  :param train_state: a dictionary representing the training state values\n","  :returns:\n","      a new train_state\n","  \"\"\"\n","  torch.save(model.state_dict(), train_state['model_filename']+\"_\"+str(train_state['epoch_index']+8)+\".pth\")\n","  # Save one model at least\n","  if train_state['epoch_index'] == 0:\n","    # torch.save(model.state_dict(), train_state['model_filename'])\n","    train_state['stop_early'] = False\n","\n","  # Save model if performance improved\n","  elif train_state['epoch_index'] >= 1:\n","    loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","    # If loss worsened\n","    if loss_t >= train_state['early_stopping_best_val']:\n","      # Update step\n","      train_state['early_stopping_step'] += 1\n","    # Loss decreased\n","    else:\n","      # Save the best model\n","      # if loss_t < train_state['early_stopping_best_val']:\n","      #     torch.save(model.state_dict(), train_state['model_filename']+\"_\"+str(train_state['epoch_index']+11)+\".pth\")\n","      # Reset early stopping step\n","      train_state['early_stopping_step'] = 0\n","\n","    # Stop early ?\n","    train_state['stop_early'] = \\\n","        train_state['early_stopping_step'] >= args.early_stopping_criteria\n","  return train_state\n","\n","def compute_accuracy(y_pred, y_target):\n","  _, y_pred_indices = y_pred.max(dim=1)\n","  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","  return n_correct / len(y_pred_indices) * 100"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ig-lwAAkh0w"},"source":["###Initializations"]},{"cell_type":"code","metadata":{"id":"zhbuS8_ZkiE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617307742984,"user_tz":-180,"elapsed":19159,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"48e45961-e42a-413d-aef3-f08e9180be0e"},"source":["if args.expand_filepaths_to_save_dir:\n","  args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n","  args.reload_name = os.path.join(args.save_dir, args.reload_name)\n","  print(\"Expanded filepaths: \")\n","  print(\"\\t{}\".format(args.model_state_file))\n","  print(\"\\t{}\".format(args.reload_name))\n","\n","# Set seed for reproducibility\n","set_seed_everywhere(args.seed, args.cuda)\n","\n","# handle dirs\n","# handle_dirs(args.save_dir)\n","\n","dataset = LegalDataset()\n","vectorizer = dataset.get_vectorizer()\n","classifier = LegalClassifier(no_classes=args.no_classes)\n","\n","if args.reload_from_files:\n","    # training from a checkpoint\n","    print(\"Reloading previous model!\")\n","    classifier.load_state_dict(torch.load(args.reload_name, map_location=torch.device(args.device)))\n","else:\n","    print(\"Creating fresh!\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Expanded filepaths: \n","\t/content/drive/MyDrive/thesis/model_chapter_test\n","\t/content/drive/MyDrive/thesis/model_chapter_test_7.pth\n","loading validation set...\n","loading training set...\n","loading test set...\n","Processing dataset...\n","Loading BERT tokenizer...\n","Done\n","Loading greek-Bert...\n","Reloading previous model!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f1h5wBjHw_Gs"},"source":["###Training Loop"]},{"cell_type":"code","metadata":{"id":"lMdq50aOw_Mr","colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["3a7bfdd56d034a83b4cb6b08a7b1f084","19e5403526f9402dbc04260d2f1852af","78b81d3885614af7a93e88ee22202b8e","78184c00aae0491392f52fc25d2a468e","4c4a250a9d994691ab110949705e2142","106c6c26a21c4177b4d9e4eaa36e1e66","6c33324715634bebb3434a872deeeec7","89fbffdd1eb0450c92ece74ee75d8f21","c0b0fd731d66464c9914b356bf4c4b25","ebb5e793fb194afd93aba656b20dde70","3c50adfdf9394c1ab871a56aac39dc7c","214cb2adddb74e1fb14fe821a037e762","5fd74b00842f45d49f3e675b7ea952d4","6414f05fc8e84915bef8aaf678625421","b154a9a60d114cf981777e378b6a3b7f","db42598ea88e4d55b592f397031cb4c8","0b9435e6a026496c9b2b06b3e124739b","1493053b54d34697b8a1a0e3b1d2809c","01e952edf0d046e584ba9ed5e2edcd17","01bf44a410244c23ae30e20d721324d5","304b9828a0284d1db45ed35150337280","a615c51c7a6249b785f0cae0a3a68973","f0d7b0fb6dad492abec45600bb3d0947","eb3301682f224ec186fe5935b6e81619"]},"executionInfo":{"status":"ok","timestamp":1617308035129,"user_tz":-180,"elapsed":311294,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"2fd97379-ec3c-4a55-f925-cecb5bebe403"},"source":["classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","loss_func = nn.CrossEntropyLoss()#weight=dataset.class_weights)\n","optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n","                                                 mode='min', factor=0.5, patience=1) #adjusts learning rate\n","     #torch.optim.lr_scheduler provides several methods to adjust the learning rate based on \n","     #the number of epochs. torch.optim.lr_scheduler.ReduceLROnPlateau allows dynamic \n","     #learning rate reducing based on some validation measurements.\n","\n","train_state = make_train_state(args)\n","\n","epoch_bar = tqdm(desc='training routine', \n","                          total=args.num_epochs,\n","                          position=0)\n","\n","dataset.set_split('train')\n","train_bar = tqdm(desc='split=train',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","dataset.set_split('val')\n","val_bar = tqdm(desc='split=val',\n","                        total=dataset.get_num_batches(args.batch_size), \n","                        position=1, \n","                        leave=True)\n","\n","try:\n","  for epoch_index in range(args.num_epochs):\n","    train_state['epoch_index'] = epoch_index\n","\n","    # Iterate over training dataset\n","\n","    # setup: batch generator, set loss and acc to 0, set train mode on\n","\n","    dataset.set_split('train')\n","    batch_generator = generate_batches(dataset, \n","                                        batch_size=args.batch_size, \n","                                        device=args.device)\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    classifier.train()\n","\n","    for batch_index, batch_dict in enumerate(batch_generator):\n","      # the training routine is these 5 steps:\n","\n","      # --------------------------------------\n","      # step 1. zero the gradients\n","      optimizer.zero_grad()\n","      # step 2. compute the output\n","      y_pred = classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","      # step 3. compute the loss\n","      loss = loss_func(y_pred, batch_dict['target'])\n","      loss_t = loss.item()\n","      running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","      # step 4. use loss to produce gradients\n","      loss.backward()\n","\n","      # step 5. use optimizer to take gradient step\n","      optimizer.step()\n","      # -----------------------------------------\n","      # compute the accuracy\n","      acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","      running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","      # update bar\n","      train_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                      epoch=epoch_index)\n","      train_bar.update()\n","\n","    train_state['train_loss'].append(running_loss)\n","    train_state['train_acc'].append(running_acc)\n","\n","    # Iterate over val dataset\n","\n","    # setup: batch generator, set loss and acc to 0; set eval mode on\n","    dataset.set_split('val')\n","    batch_generator = generate_batches(dataset, \n","                                        batch_size=args.batch_size, \n","                                        device=args.device)\n","    running_loss = 0.\n","    running_acc = 0.\n","    classifier.eval()\n","    with torch.no_grad():\n","      for batch_index, batch_dict in enumerate(batch_generator):\n","        # compute the output\n","        y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","\n","        # compute the loss\n","        loss = loss_func(y_pred, batch_dict['target'])\n","        loss_t = loss.to(\"cpu\").item()\n","        running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","        # compute the accuracy\n","        acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","        running_acc += (acc_t - running_acc) / (batch_index + 1)\n","        val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                        epoch=epoch_index)\n","        \n","        val_bar.update()\n","\n","    train_state['val_loss'].append(running_loss)\n","    train_state['val_acc'].append(running_acc)\n","\n","    train_state = update_train_state(args=args, model=classifier,\n","                                      train_state=train_state)\n","\n","    scheduler.step(train_state['val_loss'][-1])\n","\n","    if train_state['stop_early']:\n","      break\n","\n","    train_bar.n = 0\n","    val_bar.n = 0\n","    epoch_bar.update()\n","except KeyboardInterrupt:\n","    print(\"Exiting loop\")"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a7bfdd56d034a83b4cb6b08a7b1f084","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', max=15.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0b0fd731d66464c9914b356bf4c4b25","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=445.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b9435e6a026496c9b2b06b3e124739b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=148.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Exiting loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GwHo8Wr5aeIc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617308035131,"user_tz":-180,"elapsed":311290,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"b245b1b5-bf6e-4971-cd0d-99b3913faf29"},"source":["print(train_state['val_acc'])\n","print(train_state['val_loss'])\n","print(train_state['train_loss'])\n","print(train_state['train_acc'])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[75.23226351351353]\n","[1.3653551267611017]\n","[0.10330134446868737]\n","[98.32162921348312]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DzRDHukTMn8T","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1617308035132,"user_tz":-180,"elapsed":311281,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"0aa592f7-e5fb-4951-f1b2-0fb107f5394d"},"source":["# compute the metrics on the test set using the best available model\n","\n","classifier.load_state_dict(torch.load(args.model_state_file))\n","\n","classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","loss_func = nn.CrossEntropyLoss()#weight=dataset.class_weights)\n","\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","\n","test_bar = tqdm(desc='split=test',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","metric_collection = MetricCollection([\n","    Accuracy(),\n","    Precision(num_classes=args.no_classes, average='micro'),\n","    Recall(num_classes=args.no_classes, average='micro'),\n","    F1(num_classes=args.no_classes, average='micro')\n","]).to(args.device)\n","\n","classifier.eval()\n","with torch.no_grad():\n","  for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute the output\n","    y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","\n","    # compute the metrics\n","    metric_collection.update(y_pred, batch_dict['target'])\n","    test_bar.update()\n","\n","metrics = metric_collection.compute()\n","print(metrics)"],"execution_count":17,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-11bb3ba3a225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute the metrics on the test set using the best available model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_state_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/thesis/model_chapter_test'"]}]}]}