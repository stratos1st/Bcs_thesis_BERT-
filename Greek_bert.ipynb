{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Greek_bert.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOXyWu7I+9cg2hSjXVZRNWx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ed3547366bda47f09c8df52e4af0c1f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7986aaa648694b49a97ea7988e8ebceb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_67beaab97b1948f7854d0f90b482d38c","IPY_MODEL_bd8ba8e7d94a44b3a66f11a2f257a3ea"]}},"7986aaa648694b49a97ea7988e8ebceb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67beaab97b1948f7854d0f90b482d38c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4e7ff966ebaf44009e1e033f420075b7","_dom_classes":[],"description":"training routine: 100%","_model_name":"FloatProgressModel","bar_style":"","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_423fd7190ba74cc98394ca1745a1be49"}},"bd8ba8e7d94a44b3a66f11a2f257a3ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_62f6f0ea37e544b7a7c8c01f0583b303","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [2:49:57&lt;00:00, 3399.61s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb7fcc9d9183488f8a8cd950c7f5d810"}},"4e7ff966ebaf44009e1e033f420075b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"423fd7190ba74cc98394ca1745a1be49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62f6f0ea37e544b7a7c8c01f0583b303":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fb7fcc9d9183488f8a8cd950c7f5d810":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9400e1175e4a415fbea4d7618cb5ad02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1e2e06aad8cd49bc8a261124aa486ded","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e6a7ce728d8345dc94e9b62e37c49f7b","IPY_MODEL_b2cc005e5c704866be685da0bb31edf3"]}},"1e2e06aad8cd49bc8a261124aa486ded":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6a7ce728d8345dc94e9b62e37c49f7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_537999c8818a4101bc7f26de43c7a3be","_dom_classes":[],"description":"split=train: 100%","_model_name":"FloatProgressModel","bar_style":"","max":3567,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3566,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0978fc8dddaa4b3f8bce873f28b7df1a"}},"b2cc005e5c704866be685da0bb31edf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_28c92d6d7716448cb0cec5532e41a891","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3566/3567 [2:43:42&lt;00:00,  1.17it/s, acc=88.5, epoch=2, loss=0.819]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0aa9736ac7064bfea579b9bcb0230a28"}},"537999c8818a4101bc7f26de43c7a3be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0978fc8dddaa4b3f8bce873f28b7df1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28c92d6d7716448cb0cec5532e41a891":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0aa9736ac7064bfea579b9bcb0230a28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"414b128de74e48e3ba9c0f302dca6905":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b9427fb64e8343e8a9ac791db94c66e7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f89da1477d2f4501b381473d44295bc6","IPY_MODEL_a139016bf4cc4c79928faf50d07b641d"]}},"b9427fb64e8343e8a9ac791db94c66e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f89da1477d2f4501b381473d44295bc6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d9db28496ada4cfd80058fe255e6d450","_dom_classes":[],"description":"split=val: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1188,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1187,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_990d95d843994ae580bee4b7482f3cf4"}},"a139016bf4cc4c79928faf50d07b641d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_68f63db63842407a8f0098986be6aeb4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1187/1188 [2:49:56&lt;00:00,  3.19it/s, acc=72.5, epoch=2, loss=1.6]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4c93794a7b7464f87bafed2dc8487b2"}},"d9db28496ada4cfd80058fe255e6d450":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"990d95d843994ae580bee4b7482f3cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68f63db63842407a8f0098986be6aeb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b4c93794a7b7464f87bafed2dc8487b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdfe43776bff4c658617b2db3e578fe2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4ff518ee33c4833b65304782b6933fd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b740285104484890b38c74666175459b","IPY_MODEL_865b436577444d8f82ee71cd169b1e16"]}},"a4ff518ee33c4833b65304782b6933fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b740285104484890b38c74666175459b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_af0bbff88ccb41f8b343e59dcd0fab5e","_dom_classes":[],"description":"split=test: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1189,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1189,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_40932bd1cbfc4096948fbd425e29bebc"}},"865b436577444d8f82ee71cd169b1e16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d3711b61b9e0454391f62f5f522f03d1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1189/1189 [06:16&lt;00:00,  3.15it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_85376c00c0f345d0b0d583c2c05a8b7e"}},"af0bbff88ccb41f8b343e59dcd0fab5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"40932bd1cbfc4096948fbd425e29bebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3711b61b9e0454391f62f5f522f03d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"85376c00c0f345d0b0d583c2c05a8b7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EEDBycDQOHOY","executionInfo":{"status":"ok","timestamp":1616880746282,"user_tz":-120,"elapsed":668,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["from argparse import Namespace\n","args = Namespace(\n","  # Data and path information\n","  dataset_path=\"/content/drive/MyDrive/thesis/dataset/\",\n","  model_state_file=\"model_subject2.pth\",\n","  save_dir=\"/content/drive/MyDrive/thesis/\",\n","  no_classes = 2285,\n","  class_name = 'subject',\n","  # Training hyper parameters\n","  seed=1337,\n","  num_epochs=3,\n","  early_stopping_criteria=100,\n","  learning_rate=0.00001,\n","  batch_size=8,\n","  # Runtime options\n","  cuda=True,\n","  reload_from_files=False,\n","  expand_filepaths_to_save_dir=True,\n",")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uHTL519iZVZ"},"source":["###tmp"]},{"cell_type":"code","metadata":{"id":"9N1VlTthMldd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616880746653,"user_tz":-120,"elapsed":1030,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"1d2f7098-6b99-4bf3-8653-507bc460df26"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive') "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rqkz0Hg1O2Up","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616880752038,"user_tz":-120,"elapsed":6404,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"6bde9fbd-f293-473d-dd09-8319e7ed8945"},"source":["# from collections import Counter\n","\n","# import string\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","# https://torchmetrics.readthedocs.io/en/latest/index.html\n","!pip install torchmetrics\n","from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1\n","\n","# reading json files\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","\n","# huggingface lib bert\n","print('Loading transformers lib...')\n","!pip install transformers\n","from transformers import AutoTokenizer, AutoModel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.8.0+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\n","Loading transformers lib...\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VlFvFQUvOAcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616880752048,"user_tz":-120,"elapsed":6403,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"b4de79e0-3a60-457f-f7e8-55d8b685358c"},"source":["# Check CUDA and gpu available\n","if not torch.cuda.is_available():\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Using CUDA: {}\".format(args.cuda))\n","if args.cuda:\n","  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using CUDA: True\n","GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EsVjpIsZKA4d"},"source":["###Transform dataset\n","transform json files to dataframes and save them as pickles"]},{"cell_type":"code","metadata":{"id":"8c0Ro4GK7WsL","executionInfo":{"status":"ok","timestamp":1616880752050,"user_tz":-120,"elapsed":6397,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# original_dataset_path = \"/content/drive/MyDrive/RAPTARCHIS47k/\"\n","\n","# def transform_save_data(path):\n","#   \"\"\"\n","#     transforms jason original dataset to dataframe and saves it to pickle \n","#   \"\"\"\n","#   df = pd.DataFrame(columns = column_names)\n","  \n","#   path1 = join(original_dataset_path,path)\n","#   bar = tqdm(desc=path, total=len(listdir(path1)), \n","#               position=1, leave=True)\n","  \n","#   for f in listdir(path1):\n","#     path2 = join(path1, f)\n","#     if isfile(path2):\n","#       with open(path2) as json_file:\n","#         data = json.load(json_file)\n","#         tmp = pd.Series([data['title'], data['type'], data['year'], \n","#                     data['law_id'] if data['law_id'] is not None else \"None\",\n","#                     data['leg_uri'] if data['leg_uri'] is not None else \"None\",\n","#                   data['volume'], data['chapter'], data['subject'], data['header'],\n","#                   data['header']], index = column_names)\n","#         df = df.append(tmp, ignore_index=True)\n","#         bar.update()\n","#   df.to_pickle(join(args.save_dir,'dataset/',path+'.pkl'))\n","\n","\n","# column_names=['title', 'type', 'year', 'law_id', 'leg_uri', \n","#               'volume', 'chapter', 'subject', 'header', 'articles']\n","# train_df = pd.DataFrame(columns = column_names)\n","# val_df = pd.DataFrame(columns = column_names)\n","# test_df = pd.DataFrame(columns = column_names)\n","\n","# transform_save_data('test')\n","# transform_save_data('dev')\n","# transform_save_data('train')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUbFqZMTYFOy"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"x5SVi3W8YFUb","executionInfo":{"status":"ok","timestamp":1616880752051,"user_tz":-120,"elapsed":6391,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def set_seed_everywhere(seed, cuda):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  # random.seed(seed)\n","  # !!!! may need to add hugingface init seed\n","  if cuda:\n","    torch.cuda.manual_seed_all(seed)\n","\n","def handle_dirs(dirpath):\n","  if not os.path.exists(dirpath):\n","    os.makedirs(dirpath)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A89dNcfGViGB"},"source":["### The Vectorizer"]},{"cell_type":"code","metadata":{"id":"8jG3SJWzViOn","executionInfo":{"status":"ok","timestamp":1616880752053,"user_tz":-120,"elapsed":6387,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalVectorizer(object):\n","  \"\"\" The Vectorizer\"\"\"\n","  def __init__(self, max_len=0):\n","    \"\"\"\n","    Args:\n","        LegalVectorizer (max_len): maps characters to integers and pads to max_len\n","    \"\"\"\n","    print('Loading BERT tokenizer...')\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\", model_max_length=512)\n","    self.max_len = max_len\n","\n","  def vectorize(self, text):\n","    \"\"\"\n","    Args:\n","        text (list of str):\n","    Returns:\n","        dictionary: \"vector\" is a tensor with a list of encoded text paded to max_len, ready for import to BERT\n","                    \"mask\" is a tensor with a list of masks ready for import to BERT\n","    \"\"\"\n","    encoded_dict = self.tokenizer(\n","                    text,                      # Sentence to encode.\n","                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                    # padding = 'longest', # pad to longest in bach\n","                    truncation = True, # truncates sentenses to 512, max bert length\n","                    padding = 'max_length',\n","                    # max_length = 512,           # Pad\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',     # Return pytorch tensors.\n","                )\n","\n","    return {\"vector\" : encoded_dict['input_ids'],\n","            \"mask\" : encoded_dict['attention_mask']}\n","\n","  def to_words(self, vector, remove_pads=True):\n","    \"\"\"\n","    Args:\n","        vector (tensor): list of vectors to decode\n","        remove_pads : remove pad \n","    Returns:\n","        list of lists of words coresponding to the vector values\n","    \"\"\"\n","    if remove_pads:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v[v.nonzero()]) for v in vector]\n","    else:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v) for v in vector]\n","    return ans\n","      "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNJNFcFXZItO","executionInfo":{"status":"ok","timestamp":1616880752053,"user_tz":-120,"elapsed":6383,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# vec=LegalVectorizer(20)\n","# batch_sentences = [\"δεν ξερω αμα δουλευει\",\n","#                    \"και\"]\n","# a=vec.vectorize(batch_sentences)\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CL6zGRvng0cb"},"source":["###The dataset"]},{"cell_type":"code","metadata":{"id":"9OVA8YQTg0QD","executionInfo":{"status":"ok","timestamp":1616880752054,"user_tz":-120,"elapsed":6379,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalDataset(Dataset):\n","  def __init__(self):\n","    \"\"\"\n","    Args:\n","    \"\"\"\n","\n","    print(\"loading validation set...\")\n","    self.val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","    self.validation_size = len(self.val_df)\n","    print(\"loading training set...\")\n","    self.train_df = pd.read_pickle(args.dataset_path + \"train.pkl\")\n","    self.train_size = len(self.train_df)\n","    print(\"loading test set...\")\n","    self.test_df = pd.read_pickle(args.dataset_path + \"test.pkl\")\n","    self.test_size = len(self.test_df)\n","    # check the dataset size (dataset has extra files when aploaded to google drive. it mekes copies ex. \"123 (1).json\")\n","    if self.val_df.shape[0]!=9511 or self.train_df.shape[0]!=28536 or self.test_df.shape[0]!=9516:\n","      print(self.val_df.shape[0])\n","      print(self.train_df.shape[0])\n","      print(self.test_df.shape[0])\n","      print(\"!! ERROR dataset size !!\")\n","      exit()\n","\n","    print(\"Processing dataset...\")\n","    # replace class names with 0-n numbers\n","    class_names = pd.concat([ self.val_df[args.class_name],\n","                             self.train_df[args.class_name],\n","                             self.test_df[args.class_name] ]).unique()\n","    self.class_names = dict(zip(class_names, range(len(class_names))))\n","    self.val_df[args.class_name] = self.val_df[args.class_name].replace(self.class_names)\n","    self.train_df[args.class_name] = self.train_df[args.class_name].replace(self.class_names)\n","    self.test_df[args.class_name] = self.test_df[args.class_name].replace(self.class_names)\n","    # delete usless stuff\n","    self.val_df = self.val_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri', 'header'], axis=1)\n","    self.train_df = self.train_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri', 'header'], axis=1)\n","    self.test_df = self.test_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri', 'header'], axis=1)\n","\n","    self._vectorizer = LegalVectorizer()\n","    self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                          'val': (self.val_df, self.validation_size),\n","                          'test': (self.test_df, self.test_size)}\n","\n","    self.set_split('train')\n","\n","    print(\"Done\")\n","    # Class weights\n","    # class_counts = df['target'].value_counts().to_dict()\n","    # print(class_counts)\n","    # def sort_key(item):\n","    #     return self._vectorizer.vocab.lookup_token(item[0])\n","    # sorted_counts = sorted(class_counts.items(), key=sort_key)\n","    # frequencies = [count for _, count in sorted_counts] ; \n","    # print(frequencies)\n","    # self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n","    # print(torch.tensor(frequencies, dtype=torch.float32))\n","    # print(self.class_weights)\n","\n","  def get_vectorizer(self):\n","      \"\"\" returns the vectorizer \"\"\"\n","      return self._vectorizer\n","\n","  def set_split(self, split):\n","      \"\"\" selects the splits in the dataset using _lookup_dict \"\"\"\n","      # self._target_split = split\n","      self._target_df, self._target_size = self._lookup_dict[split]\n","\n","  def __len__(self):\n","      return self._target_size\n","\n","  def __getitem__(self, index):\n","      \"\"\"the primary entry point method for PyTorch datasets\n","      Args:\n","          index (int): the index to the data point \n","      Returns:\n","          a dictionary holding the data point's:\n","              features (x_surname)\n","              label (y_nationality)\n","      \"\"\"\n","      row = self._target_df.iloc[index]\n","      # id =  row['law_id']\n","      volume = row[args.class_name]\n","      # chapter = row['chapter']\n","      # subject = row['subject']\n","      # title type header ????\n","      tmp = self._vectorizer.vectorize(row['articles'])\n","      mask, vector = tmp['mask'], tmp['vector']\n","\n","      return {#'id': id,\n","              'volume': volume,\n","              #'chapter': chapter,\n","              #'subject': subject,\n","              'vector': vector,\n","              'mask' : mask}\n","\n","  def get_num_batches(self, batch_size):\n","      \"\"\"Given a batch size, return the number of batches in the dataset\n","      Args:\n","          batch_size (int)\n","      Returns:\n","          number of batches in the dataset\n","      \"\"\"\n","      return len(self) // batch_size"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBAMThqhdzPI","executionInfo":{"status":"ok","timestamp":1616880752056,"user_tz":-120,"elapsed":6369,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["# val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","# vec=LegalVectorizer(20)\n","# a=vec.vectorize(val_df['articles'][0])\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5SEw2hUfv5G"},"source":["###Dataloader"]},{"cell_type":"code","metadata":{"id":"-q4zXTEffv_V","executionInfo":{"status":"ok","timestamp":1616880752056,"user_tz":-120,"elapsed":6362,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"): \n","    \"\"\"\n","    A generator function which wraps the PyTorch DataLoader. It will \n","      ensure each tensor is on the write device location.\n","    \"\"\"\n","    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                            shuffle=shuffle, drop_last=drop_last)\n","\n","    for data_dict in dataloader:\n","        out_data_dict = {}\n","        for name, tensor in data_dict.items():\n","            out_data_dict[name] = data_dict[name].to(device)\n","        yield out_data_dict"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMPeoqpOf7p3"},"source":["###The Model"]},{"cell_type":"code","metadata":{"id":"3GJCeb23f7wa","executionInfo":{"status":"ok","timestamp":1616880752404,"user_tz":-120,"elapsed":6706,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["class LegalClassifier(nn.Module):\n","  \"\"\" greek-Bert model with an extra linear layer, which takes \n","      the cls tocken as input, for classification \"\"\"\n","  def __init__(self, no_classes):\n","    \"\"\"\n","    Args:\n","        no_classes (int): the size of the linear layer\n","    \"\"\"\n","    super(LegalClassifier, self).__init__()\n","    print(\"Loading greek-Bert...\")\n","    self.bert = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","    self.dropout = nn.Dropout(0.1)\n","    self.fc = nn.Linear(768,no_classes)\n","    # for param in self.bert.parameters():\n","    #   param.requires_grad = False\n","\n","  def forward(self, input, mask, apply_softmax=False):\n","    \"\"\"The forward pass of the classifier\n","    Args:\n","        input (torch.Tensor): an input data tensor. \n","                shape should be (batch, input_dim)\n","        mask (torch.Tensor): the coresponding masks for BERT\n","    Returns:\n","        the resulting tensor. tensor.shape should be (batch, output_dim)\n","    \"\"\"\n","    output = self.bert(input_ids=input, attention_mask=mask, \n","                       output_attentions=False, output_hidden_states=False)\n","    x = output[0][:,0,:] # [0][0] coresponds to CLS token\n","    x = self.dropout(x) \n","    x = self.fc(x)\n","    if apply_softmax:\n","        x = F.softmax(x, dim=1)\n","    return x"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oujVuInLieHc"},"source":["###helper functions"]},{"cell_type":"code","metadata":{"id":"wEbV1KG-ieOs","executionInfo":{"status":"ok","timestamp":1616880752413,"user_tz":-120,"elapsed":6712,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}}},"source":["def make_train_state(args):\n","  return {'stop_early': False,\n","          'early_stopping_step': 0,\n","          'early_stopping_best_val': 1e8,\n","          'learning_rate': args.learning_rate,\n","          'epoch_index': 0,\n","          'train_loss': [],\n","          'train_acc': [],\n","          'val_loss': [],\n","          'val_acc': [],\n","          'test_loss': -1,\n","          'test_acc': -1,\n","          'model_filename': args.model_state_file}\n","\n","def update_train_state(args, model, train_state):\n","  \"\"\"Handle the training state updates.\n","\n","  Components:\n","    - Early Stopping: Prevent overfitting.\n","    - Model Checkpoint: Model is saved if the model is better\n","\n","  :param args: main arguments\n","  :param model: model to train\n","  :param train_state: a dictionary representing the training state values\n","  :returns:\n","      a new train_state\n","  \"\"\"\n","\n","  # Save one model at least\n","  if train_state['epoch_index'] == 0:\n","    torch.save(model.state_dict(), train_state['model_filename'])\n","    train_state['stop_early'] = False\n","\n","  # Save model if performance improved\n","  elif train_state['epoch_index'] >= 1:\n","    loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","    # If loss worsened\n","    if loss_t >= train_state['early_stopping_best_val']:\n","      # Update step\n","      train_state['early_stopping_step'] += 1\n","    # Loss decreased\n","    else:\n","      # Save the best model\n","      if loss_t < train_state['early_stopping_best_val']:\n","          torch.save(model.state_dict(), train_state['model_filename'])\n","      # Reset early stopping step\n","      train_state['early_stopping_step'] = 0\n","\n","    # Stop early ?\n","    train_state['stop_early'] = \\\n","        train_state['early_stopping_step'] >= args.early_stopping_criteria\n","\n","  return train_state\n","\n","def compute_accuracy(y_pred, y_target):\n","  _, y_pred_indices = y_pred.max(dim=1)\n","  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","  return n_correct / len(y_pred_indices) * 100"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ig-lwAAkh0w"},"source":["###Initializations"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhbuS8_ZkiE4","executionInfo":{"status":"ok","timestamp":1616880763594,"user_tz":-120,"elapsed":17889,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"3e6b68ac-e15d-47e0-8d5c-c7f181789543"},"source":["if args.expand_filepaths_to_save_dir:\n","  args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n","  print(\"Expanded filepaths: \")\n","  # print(\"\\t{}\".format(args.vectorizer_file))\n","  print(\"\\t{}\".format(args.model_state_file))\n","\n","# Set seed for reproducibility\n","set_seed_everywhere(args.seed, args.cuda)\n","\n","# handle dirs\n","# handle_dirs(args.save_dir)\n","\n","if args.reload_from_files:\n","    # training from a checkpoint\n","    print(\"Reloading!\")\n","    dataset = TweetDataset.load_dataset_and_load_vectorizer(args.tweet_csv, args.vectorizer_file)\n","else:\n","    # create dataset and vectorizer\n","    print(\"Creating fresh!\")\n","    dataset = LegalDataset()\n","    # dataset.save_vectorizer(args.vectorizer_file)\n","    \n","vectorizer = dataset.get_vectorizer()\n","classifier = LegalClassifier(no_classes=args.no_classes)\n","classifier.load_state_dict(torch.load(\"/content/drive/MyDrive/thesis/model_subject.pth\"))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Expanded filepaths: \n","\t/content/drive/MyDrive/thesis/model_subject2.pth\n","Creating fresh!\n","loading validation set...\n","loading training set...\n","loading test set...\n","Processing dataset...\n","Loading BERT tokenizer...\n","Done\n","Loading greek-Bert...\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"f1h5wBjHw_Gs"},"source":["###Training Loop"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["ed3547366bda47f09c8df52e4af0c1f8","7986aaa648694b49a97ea7988e8ebceb","67beaab97b1948f7854d0f90b482d38c","bd8ba8e7d94a44b3a66f11a2f257a3ea","4e7ff966ebaf44009e1e033f420075b7","423fd7190ba74cc98394ca1745a1be49","62f6f0ea37e544b7a7c8c01f0583b303","fb7fcc9d9183488f8a8cd950c7f5d810","9400e1175e4a415fbea4d7618cb5ad02","1e2e06aad8cd49bc8a261124aa486ded","e6a7ce728d8345dc94e9b62e37c49f7b","b2cc005e5c704866be685da0bb31edf3","537999c8818a4101bc7f26de43c7a3be","0978fc8dddaa4b3f8bce873f28b7df1a","28c92d6d7716448cb0cec5532e41a891","0aa9736ac7064bfea579b9bcb0230a28","414b128de74e48e3ba9c0f302dca6905","b9427fb64e8343e8a9ac791db94c66e7","f89da1477d2f4501b381473d44295bc6","a139016bf4cc4c79928faf50d07b641d","d9db28496ada4cfd80058fe255e6d450","990d95d843994ae580bee4b7482f3cf4","68f63db63842407a8f0098986be6aeb4","b4c93794a7b7464f87bafed2dc8487b2"]},"id":"lMdq50aOw_Mr","executionInfo":{"status":"ok","timestamp":1616890959685,"user_tz":-120,"elapsed":10213973,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"c78e2f5c-eaa6-4016-cf23-0ff438588b80"},"source":["classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","loss_func = nn.CrossEntropyLoss()#dataset.class_weights)\n","optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n","                                                 mode='min', factor=0.5, patience=1) #adjusts learning rate\n","     #torch.optim.lr_scheduler provides several methods to adjust the learning rate based on \n","     #the number of epochs. torch.optim.lr_scheduler.ReduceLROnPlateau allows dynamic \n","     #learning rate reducing based on some validation measurements.\n","\n","train_state = make_train_state(args)\n","\n","epoch_bar = tqdm(desc='training routine', \n","                          total=args.num_epochs,\n","                          position=0)\n","\n","dataset.set_split('train')\n","train_bar = tqdm(desc='split=train',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","dataset.set_split('val')\n","val_bar = tqdm(desc='split=val',\n","                        total=dataset.get_num_batches(args.batch_size), \n","                        position=1, \n","                        leave=True)\n","\n","try:\n","  for epoch_index in range(args.num_epochs):\n","    train_state['epoch_index'] = epoch_index\n","\n","    # Iterate over training dataset\n","\n","    # setup: batch generator, set loss and acc to 0, set train mode on\n","\n","    dataset.set_split('train')\n","    batch_generator = generate_batches(dataset, \n","                                        batch_size=args.batch_size, \n","                                        device=args.device)\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    classifier.train()\n","\n","    for batch_index, batch_dict in enumerate(batch_generator):\n","      # the training routine is these 5 steps:\n","\n","      # --------------------------------------\n","      # step 1. zero the gradients\n","      optimizer.zero_grad()\n","      # step 2. compute the output\n","      y_pred = classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","      # step 3. compute the loss\n","      loss = loss_func(y_pred, batch_dict['volume'])\n","      loss_t = loss.item()\n","      running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","      # step 4. use loss to produce gradients\n","      loss.backward()\n","\n","      # step 5. use optimizer to take gradient step\n","      optimizer.step()\n","      # -----------------------------------------\n","      # compute the accuracy\n","      acc_t = compute_accuracy(y_pred, batch_dict['volume'])\n","      running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","      # update bar\n","      train_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                      epoch=epoch_index)\n","      train_bar.update()\n","\n","    train_state['train_loss'].append(running_loss)\n","    train_state['train_acc'].append(running_acc)\n","\n","    # Iterate over val dataset\n","\n","    # setup: batch generator, set loss and acc to 0; set eval mode on\n","    dataset.set_split('val')\n","    batch_generator = generate_batches(dataset, \n","                                        batch_size=args.batch_size, \n","                                        device=args.device)\n","    running_loss = 0.\n","    running_acc = 0.\n","    classifier.eval()\n","    with torch.no_grad():\n","      for batch_index, batch_dict in enumerate(batch_generator):\n","        # compute the output\n","        y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","\n","        # compute the loss\n","        loss = loss_func(y_pred, batch_dict['volume'])\n","        loss_t = loss.to(\"cpu\").item()\n","        running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","        # compute the accuracy\n","        acc_t = compute_accuracy(y_pred, batch_dict['volume'])\n","        running_acc += (acc_t - running_acc) / (batch_index + 1)\n","        val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                        epoch=epoch_index)\n","        \n","        val_bar.update()\n","\n","    train_state['val_loss'].append(running_loss)\n","    train_state['val_acc'].append(running_acc)\n","\n","    train_state = update_train_state(args=args, model=classifier,\n","                                      train_state=train_state)\n","\n","    scheduler.step(train_state['val_loss'][-1])\n","\n","    # if train_state['stop_early']:\n","    #   break\n","\n","    train_bar.n = 0\n","    val_bar.n = 0\n","    epoch_bar.update()\n","except KeyboardInterrupt:\n","    print(\"Exiting loop\")"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed3547366bda47f09c8df52e4af0c1f8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', max=3.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9400e1175e4a415fbea4d7618cb5ad02","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=3567.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"414b128de74e48e3ba9c0f302dca6905","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=1188.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"GwHo8Wr5aeIc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616890959687,"user_tz":-120,"elapsed":10213968,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"b6202afe-5bfe-4757-abb5-7175d0473c32"},"source":["print(train_state['val_acc'])\n","print(train_state['val_loss'])\n","print(train_state['train_loss'])\n","print(train_state['train_acc'])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[69.42340067340069, 70.78072390572399, 72.54840067340061]\n","[1.8467014563216624, 1.7206001723175761, 1.6000770755184306]\n","[1.375827096559302, 1.0599832386781, 0.8186426937720073]\n","[78.72161480235489, 84.2479674796748, 88.47070367255392]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DzRDHukTMn8T","colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["bdfe43776bff4c658617b2db3e578fe2","a4ff518ee33c4833b65304782b6933fd","b740285104484890b38c74666175459b","865b436577444d8f82ee71cd169b1e16","af0bbff88ccb41f8b343e59dcd0fab5e","40932bd1cbfc4096948fbd425e29bebc","d3711b61b9e0454391f62f5f522f03d1","85376c00c0f345d0b0d583c2c05a8b7e"]},"executionInfo":{"status":"ok","timestamp":1616891336468,"user_tz":-120,"elapsed":10590741,"user":{"displayName":"1strman","photoUrl":"","userId":"01784038301378029157"}},"outputId":"e2a9c772-73bf-4519-c7fd-82cf39e3c7ee"},"source":["# compute the metrics on the test set using the best available model\n","\n","classifier.load_state_dict(torch.load(args.model_state_file))\n","\n","classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","loss_func = nn.CrossEntropyLoss()#dataset.class_weights)\n","\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","\n","test_bar = tqdm(desc='split=test',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","\n","metric_collection = MetricCollection([\n","    Accuracy(),\n","    Precision(num_classes=args.no_classes, average='micro'),\n","    Recall(num_classes=args.no_classes, average='micro'),\n","    F1(num_classes=args.no_classes, average='micro')\n","]).to(args.device)\n","\n","classifier.eval()\n","with torch.no_grad():\n","  # running_acc = 0\n","  # running_loss = 0\n","\n","  for batch_index, batch_dict in enumerate(batch_generator):\n","      # compute the output\n","      y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","      \n","      # # compute the loss\n","      # loss = loss_func(y_pred, batch_dict['volume'])\n","      # loss_t = loss.item()\n","      # running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","      # # compute the accuracy\n","      # acc_t = compute_accuracy(y_pred, batch_dict['volume'])\n","      # running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","      metric_collection.update(y_pred, batch_dict['volume'])\n","      test_bar.update()\n","\n","metrics = metric_collection.compute()\n","print(metrics)\n","# train_state['test_loss'] = running_loss\n","# train_state['test_acc'] = running_acc\n","# print(running_acc)"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdfe43776bff4c658617b2db3e578fe2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=test', max=1189.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'Accuracy': tensor(0.7258, device='cuda:0'), 'Precision': tensor(0.7258, device='cuda:0'), 'Recall': tensor(0.7258, device='cuda:0'), 'F1': tensor(0.7258, device='cuda:0')}\n"],"name":"stdout"}]}]}