{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Greek_bert.ipynb","provenance":[],"collapsed_sections":["EsVjpIsZKA4d","nUbFqZMTYFOy"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8d3724f1a72649f0a5e68e3ce72c11d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_564182f3f8a64bb980d4a29894c67919","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_757d3b55e0264502ac442384396ec504","IPY_MODEL_bda130700fc541508d8d66ea02378261"]}},"564182f3f8a64bb980d4a29894c67919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"757d3b55e0264502ac442384396ec504":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_65c0975ef84b4d5dabf3f0ef53eac680","_dom_classes":[],"description":"training routine:  60%","_model_name":"FloatProgressModel","bar_style":"","max":15,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad34a66fce1a48b2ad25ef0f548e44ae"}},"bda130700fc541508d8d66ea02378261":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b9112cf636f2475eae5b69b06e0415d9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9/15 [3:37:37&lt;2:24:38, 1446.42s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf654533b99c4824a00b46b84d02d19a"}},"65c0975ef84b4d5dabf3f0ef53eac680":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ad34a66fce1a48b2ad25ef0f548e44ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9112cf636f2475eae5b69b06e0415d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bf654533b99c4824a00b46b84d02d19a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec82c45803bc4411b7a5d5d6a31e1bf7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_35e78130132648abbc91bf01325d11cd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1bdef2a237d844f8892b748522020c1e","IPY_MODEL_011f129e41604c24b0bd458db2c2d3da"]}},"35e78130132648abbc91bf01325d11cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1bdef2a237d844f8892b748522020c1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b009ab28de5548d7995595c1192853b7","_dom_classes":[],"description":"split=train:   4%","_model_name":"FloatProgressModel","bar_style":"","max":3567,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":128,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8261b690d3d74333835acc37e2506137"}},"011f129e41604c24b0bd458db2c2d3da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ddab8d220f3745b2b8a78b480aca9abf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 128/3567 [3:38:23&lt;25:43,  2.23it/s, acc=98.7, epoch=9, loss=0.0682]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb98180034f74b2b99492b45a154ea90"}},"b009ab28de5548d7995595c1192853b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8261b690d3d74333835acc37e2506137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ddab8d220f3745b2b8a78b480aca9abf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eb98180034f74b2b99492b45a154ea90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49bf86ded83f469ba7d134bb3cbc6d3d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_23ddd2eb324d4fcd9180265c474943bb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4d4adaa2594b4c399d0b12240f8a255a","IPY_MODEL_8b21e37f8b9e4deab33b8926e914545c"]}},"23ddd2eb324d4fcd9180265c474943bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d4adaa2594b4c399d0b12240f8a255a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a963c91ac28e42349d5a2b3ee584eb9a","_dom_classes":[],"description":"split=val: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1188,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1187,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_819d44c07ad2465bb1488b52b0819bf3"}},"8b21e37f8b9e4deab33b8926e914545c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4f49feb4353249218929dc3bd5c932e4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1187/1188 [3:37:35&lt;00:00,  8.52it/s, acc=81.3, epoch=8, loss=1.01]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60dd146854284acfbaa73780c0a6646d"}},"a963c91ac28e42349d5a2b3ee584eb9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"819d44c07ad2465bb1488b52b0819bf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f49feb4353249218929dc3bd5c932e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"60dd146854284acfbaa73780c0a6646d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"672ab55a43ce4ee8ae75679d9b1e4d1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8b278fc896da4ebf8ce819c373efe7a0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1885e859f0b84871919681058a73cf94","IPY_MODEL_54575125420f4798956a4e409180944a"]}},"8b278fc896da4ebf8ce819c373efe7a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1885e859f0b84871919681058a73cf94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c9a5e2e123304b6f8f37827f235818d3","_dom_classes":[],"description":"split=test:   4%","_model_name":"FloatProgressModel","bar_style":"","max":1189,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":47,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fb536c6aa4b8498e848c807ad7ab100c"}},"54575125420f4798956a4e409180944a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_726bfd65dc6b41d2a17afe0933d5594c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 47/1189 [00:06&lt;02:32,  7.50it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8392b915bf74170a2cb2f6da1317280"}},"c9a5e2e123304b6f8f37827f235818d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fb536c6aa4b8498e848c807ad7ab100c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"726bfd65dc6b41d2a17afe0933d5594c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e8392b915bf74170a2cb2f6da1317280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"EEDBycDQOHOY","executionInfo":{"status":"ok","timestamp":1617621482575,"user_tz":-180,"elapsed":587,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["from argparse import Namespace\n","args = Namespace(\n","  # Data and path information\n","  dataset_path=\"/content/drive/MyDrive/thesis/dataset/\",\n","  model_state_file=\"model_chapter\", # final name will be model_state_file+'_'+epoch_no+'.pth'\n","  save_dir=\"/content/drive/MyDrive/thesis/\", # save models here\n","  no_classes = 389, # subject 2285, chapter 389, volume 47\n","  class_name = 'chapter',\n","  # Training hyper parameters\n","  seed=1338,\n","  num_epochs=15,\n","  early_stopping_criteria=2,\n","  learning_rate=0.00002,\n","  batch_size=8,\n","  # Runtime options\n","  cuda=True,\n","  reload_from_files=False, # to continue training from checkpoint or evaluate a model\n","  reload_name=\"model_subject_0.pth\",\n","  expand_filepaths_to_save_dir=True,\n","  train = False, # if false reload_from_files must be true, to reload and evaluate a model\n","  transform_data = False\n",")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uHTL519iZVZ"},"source":["###tmp"]},{"cell_type":"code","metadata":{"id":"9N1VlTthMldd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617621482908,"user_tz":-180,"elapsed":909,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}},"outputId":"a5aae567-59dd-41c2-c5f9-13cbc6060069"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive') "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rqkz0Hg1O2Up","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617621490520,"user_tz":-180,"elapsed":8514,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}},"outputId":"44728589-bf32-4705-e706-cac33481cc55"},"source":["# from collections import Counter\n","# import string\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from tqdm.notebook import tqdm\n","from tqdm import trange\n","\n","!pip install torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","print('Loading torchmetrics lib...')\n","# https://torchmetrics.readthedocs.io/en/latest/index.html\n","!pip install torchmetrics\n","from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1\n","\n","# reading json files\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import os\n","\n","# huggingface lib bert\n","print('Loading transformers lib...')\n","!pip install transformers\n","from transformers import AutoTokenizer, AutoModel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Loading torchmetrics lib...\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (1.19.5)\n","Loading transformers lib...\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VlFvFQUvOAcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617621490521,"user_tz":-180,"elapsed":8510,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}},"outputId":"02f220ee-f87e-46a8-8c69-02ececab0de6"},"source":["# Check CUDA and gpu available\n","if not torch.cuda.is_available():\n","  args.cuda = False\n","args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","print(\"Using CUDA: {}\".format(args.cuda))\n","if args.cuda:\n","  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using CUDA: True\n","GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EsVjpIsZKA4d"},"source":["###Transform dataset\n","transform json files to dataframes and save them as pickles. This was executed on local runtime"]},{"cell_type":"code","metadata":{"id":"8c0Ro4GK7WsL","executionInfo":{"status":"ok","timestamp":1617621490976,"user_tz":-180,"elapsed":8959,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["if args.transform_data:\n","  # computed in local runtime\n","  # original_dataset_path = \"/content/drive/MyDrive/RAPTARCHIS47k\"\n","  original_dataset_path = \"/mnt/D21005A6100592A1/ΕΚΠΑ/πτυχιακή/Bert-final/\"\n","  column_names=['title', 'type', 'year', 'law_id', 'leg_uri','volume', \n","                'chapter', 'subject', 'header', 'articles']\n","\n","  def transform_save_data(path):\n","    \"\"\"\n","      transforms jason original dataset to dataframe and saves it to pickle \n","    \"\"\"\n","    df = pd.DataFrame(columns = column_names)\n","    \n","    path1 = join(original_dataset_path,path)\n","    bar = tqdm(desc=path, total=len(listdir(path1)), \n","                position=1, leave=True)\n","\n","    articles = []\n","    for f in listdir(path1):\n","      path2 = join(path1, f)\n","      if isfile(path2):\n","        with open(path2) as json_file:\n","          data = json.load(json_file)\n","          # json to dataframe\n","                      \n","          tmp = pd.Series([data['title'], data['type'], data['year'], \n","                      data['law_id'] if data['law_id'] is not None else \"None\",\n","                      data['leg_uri'] if data['leg_uri'] is not None else \"None\",\n","                      data['volume'], data['chapter'], data['subject'], \n","                      data['header'],\"\"], index = column_names)\n","          df = df.append(tmp, ignore_index=True)\n","          # process articles list\n","          tmp2 = \"\"\n","          for i in data['articles']:\n","            tmp2 += i + \" \"\n","          articles.append(tmp2)\n","          bar.update()\n","    df['articles'] = articles\n","    # df.to_pickle(join(args.save_dir,'dataset/',path+'.pkl'))\n","    df.to_pickle(original_dataset_path+path+'.pkl')\n","\n","  train_df = pd.DataFrame(columns = column_names)\n","  val_df = pd.DataFrame(columns = column_names)\n","  test_df = pd.DataFrame(columns = column_names)\n","\n","  transform_save_data('test')\n","  transform_save_data('dev')\n","  transform_save_data('train')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUbFqZMTYFOy"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"x5SVi3W8YFUb","executionInfo":{"status":"ok","timestamp":1617621490977,"user_tz":-180,"elapsed":8955,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["# sets the seed everywhere for reprodusable results\n","def set_seed_everywhere(seed, cuda):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  # random.seed(seed)\n","  # !!!! may need to add hugingface init seed\n","  if cuda:\n","    torch.cuda.manual_seed_all(seed)\n","\n","# creates non existing directories\n","def handle_dirs(dirpath):\n","  if not os.path.exists(dirpath):\n","    os.makedirs(dirpath)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A89dNcfGViGB"},"source":["### The Vectorizer"]},{"cell_type":"code","metadata":{"id":"8jG3SJWzViOn","executionInfo":{"status":"ok","timestamp":1617621490978,"user_tz":-180,"elapsed":8951,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["class LegalVectorizer(object):\n","  \"\"\" The Vectorizer\"\"\"\n","  def __init__(self):\n","    print('Loading BERT tokenizer...')\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\", model_max_length=512)\n","\n","  def vectorize(self, text):\n","    \"\"\"\n","    Args:\n","        text (list of str):\n","    Returns:\n","        dictionary: \"vector\" is a tensor with a list of encoded text paded to max_len, ready for import to BERT\n","                    \"mask\" is a tensor with a list of masks ready for import to BERT\n","    \"\"\"\n","    encoded_dict = self.tokenizer(\n","                    text,                      \n","                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                    padding = True, # pad to longest in batch\n","                    truncation = True, # truncates sentenses to 512, max bert length\n","                    # padding = 'max_length',\n","                    # max_length = 512,           # Pad\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',     # Return pytorch tensors.\n","                )\n","    return {\"vector\" : encoded_dict['input_ids'],\n","            \"mask\" : encoded_dict['attention_mask']}\n","\n","  def get_pad_tocken(self):\n","    return self.tokenizer.pad_token_id\n","\n","  def to_words(self, vector, remove_pads=True):\n","    \"\"\"\n","    Args:\n","        vector (tensor): list of vectors to decode\n","        remove_pads : remove pad \n","    Returns:\n","        list of lists of words coresponding to the vector values\n","    \"\"\"\n","    if remove_pads:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v[v.nonzero()]) for v in vector]\n","    else:\n","      ans=[self.tokenizer.convert_ids_to_tokens(v) for v in vector]\n","    return ans\n","      "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNJNFcFXZItO","executionInfo":{"status":"ok","timestamp":1617621490979,"user_tz":-180,"elapsed":8946,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["# dataset = LegalDataset()\n","# vec=dataset.get_vectorizer()\n","# batch_sentences = [\"δεν ξερω αμα δουλευει\",\n","#                    \"και\"]\n","# a=vec.vectorize(batch_sentences)\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CL6zGRvng0cb"},"source":["###The dataset"]},{"cell_type":"code","metadata":{"id":"9OVA8YQTg0QD","executionInfo":{"status":"ok","timestamp":1617621490980,"user_tz":-180,"elapsed":8943,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["class LegalDataset(Dataset):\n","  def __init__(self):\n","    print(\"loading validation set...\")\n","    self.val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","    self.validation_size = len(self.val_df)\n","    print(\"loading training set...\")\n","    self.train_df = pd.read_pickle(args.dataset_path + \"train.pkl\")\n","    self.train_size = len(self.train_df)\n","    print(\"loading test set...\")\n","    self.test_df = pd.read_pickle(args.dataset_path + \"test.pkl\")\n","    self.test_size = len(self.test_df)\n","    # check the dataset size (dataset has extra files when uploaded to google drive. it mekes copies ex. \"123 (1).json\")\n","    if self.val_df.shape[0]!=9511 or self.train_df.shape[0]!=28536 or self.test_df.shape[0]!=9516:\n","      print(self.val_df.shape[0])\n","      print(self.train_df.shape[0])\n","      print(self.test_df.shape[0])\n","      print(\"!! ERROR dataset size !!\")\n","      exit()\n","\n","    print(\"Processing dataset...\")\n","    # replace class names with 0...n numbers\n","    class_namess = pd.concat([ self.val_df[args.class_name],\n","                             self.train_df[args.class_name],\n","                             self.test_df[args.class_name] ]).unique()\n","    self.class_names = dict(zip(class_namess, range(len(class_namess))))\n","    self.val_df[args.class_name] = self.val_df[args.class_name].replace(self.class_names)\n","    self.train_df[args.class_name] = self.train_df[args.class_name].replace(self.class_names)\n","    self.test_df[args.class_name] = self.test_df[args.class_name].replace(self.class_names)\n","    # delete usless stuff\n","    self.val_df = self.val_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.train_df = self.train_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","    self.test_df = self.test_df.drop(['title', 'type', 'year', 'law_id', 'leg_uri'], axis=1)\n","\n","    self._vectorizer = LegalVectorizer()\n","    self._lookup_dict = {'train': (self.train_df, self.train_size),\n","                          'val': (self.val_df, self.validation_size),\n","                          'test': (self.test_df, self.test_size)}\n","\n","    self.set_split('train')\n","\n","    print(\"Calculating frequences...\")\n","    self.class_counts = []\n","    for v in range(args.no_classes):\n","      tmp = self.train_df[self.train_df[args.class_name]==v][args.class_name].count()\n","      if tmp>0:\n","        self.class_counts.append(tmp)\n","      else:\n","        self.class_counts.append(0)\n","    # self.class_weights = 10000.0 / torch.tensor(self.class_counts, dtype=torch.float32) \n","\n","  def get_vectorizer(self):\n","    \"\"\" returns the vectorizer \"\"\"\n","    return self._vectorizer\n","\n","  def set_split(self, split):\n","    \"\"\" selects the splits in the dataset using _lookup_dict \"\"\"\n","    # self._target_split = split\n","    self._target_df, self._target_size = self._lookup_dict[split]\n","\n","  def __len__(self):\n","    return self._target_size\n","\n","  def __getitem__(self, index):\n","    \"\"\"the primary entry point method for PyTorch datasets\n","    Args:\n","        index (int): the index to the data point \n","    Returns:\n","        a dictionary holding the data point's. text is NOT vectorized yet.\n","    \"\"\"\n","    row = self._target_df.iloc[index]\n","    # id =  row['law_id']\n","    target = row[args.class_name]\n","    # text = row['header'] + \" \"\n","    # text += row['articles']\n","    \n","    tmp = row['header'].split()#[20:]\n","    text = \"\"\n","    for i in tmp:\n","      text += i + \" \"\n","\n","    return {#'id': id,\n","            'target': target,\n","            #'chapter': chapter,\n","            #'subject': subject,\n","            # 'vector': vector,\n","            # 'mask' : mask,\n","            'text' : text}\n","      \n","  def get_num_batches(self, batch_size):\n","    \"\"\"Given a batch size, return the number of batches in the dataset\n","    Args:\n","      batch_size (int)\n","    Returns:\n","      number of batches in the dataset\n","    \"\"\"\n","    return len(self) // batch_size"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBAMThqhdzPI","executionInfo":{"status":"ok","timestamp":1617621490980,"user_tz":-180,"elapsed":8938,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["# val_df = pd.read_pickle(args.dataset_path + \"dev.pkl\")\n","# vec=LegalVectorizer(20)\n","# a=vec.vectorize(val_df['articles'][0])\n","# print(a)\n","# print(vec.to_words(a['vector'],False))"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5SEw2hUfv5G"},"source":["###Dataloader"]},{"cell_type":"code","metadata":{"id":"-q4zXTEffv_V","executionInfo":{"status":"ok","timestamp":1617621490981,"user_tz":-180,"elapsed":8934,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["# this is a cool way to save some time in training. Havent done it yet, may effect accuracy\n","# http://mccormickml.com/2020/07/29/smart-batching-tutorial\n","def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=True, device=\"cpu\"): \n","  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                          shuffle=shuffle, drop_last=drop_last)\n","\n","  for data_dict in dataloader:\n","    #vectorize batch text\n","    tmp = dataset.get_vectorizer().vectorize(data_dict['text'])\n","    mask, vector = tmp['mask'], tmp['vector']\n","    data_dict['vector'] = vector\n","    data_dict['mask'] = mask\n","    del data_dict['text']\n","\n","    out_data_dict = {}\n","    for name, tensor in data_dict.items():\n","        out_data_dict[name] = data_dict[name].to(device)\n","    yield out_data_dict"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMPeoqpOf7p3"},"source":["###The Model"]},{"cell_type":"code","metadata":{"id":"3GJCeb23f7wa","executionInfo":{"status":"ok","timestamp":1617621490981,"user_tz":-180,"elapsed":8929,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["class LegalClassifier(nn.Module):\n","  \"\"\" greek-Bert model with an extra linear layer, which takes \n","      the cls tocken as input, for classification \"\"\"\n","  def __init__(self, no_classes):\n","    \"\"\"\n","    Args:\n","        no_classes (int): the size of the linear layer\n","    \"\"\"\n","    super(LegalClassifier, self).__init__()\n","    print(\"Loading greek-Bert...\")\n","    self.bert = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n","    self.dropout = nn.Dropout(0.1)\n","    self.fc = nn.Linear(768,no_classes)\n","    # for param in self.bert.parameters():\n","    #   param.requires_grad = False\n","\n","  def forward(self, input, mask, apply_softmax=False):\n","    \"\"\"The forward pass of the classifier\n","    Args:\n","        input (torch.Tensor): an input data tensor.\n","        mask (torch.Tensor): the coresponding masks for BERT\n","        apply_softmax (bool): whether or not to apply soflmax to the output layer\n","    Returns:\n","        the resulting tensor. tensor.shape should be (batch, output_dim)\n","    \"\"\"\n","    output = self.bert(input_ids=input, attention_mask=mask, \n","                       output_attentions=False, output_hidden_states=False)\n","    x = output.pooler_output # coresponds to CLS token\n","    x = self.dropout(x) \n","    x = self.fc(x)\n","    if apply_softmax:\n","        x = F.softmax(x, dim=1)\n","    return x"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oujVuInLieHc"},"source":["###helper functions"]},{"cell_type":"code","metadata":{"id":"wEbV1KG-ieOs","executionInfo":{"status":"ok","timestamp":1617621490982,"user_tz":-180,"elapsed":8926,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["def make_train_state(args):\n","  return {'stop_early': False,\n","          'early_stopping_step': 0,\n","          'early_stopping_best_val': 1e8,\n","          'learning_rate': args.learning_rate,\n","          'epoch_index': 0,\n","          'train_loss': [],\n","          'train_acc': [],\n","          'val_loss': [],\n","          'val_acc': [],\n","          'test_loss': -1,\n","          'test_acc': -1,\n","          'model_filename': args.model_state_file}\n","\n","def update_train_state(args, model, train_state):\n","  \"\"\"Handle the training state updates.\n","\n","  Components:\n","    - Early Stopping: Prevent overfitting.\n","    - Model Checkpoint: Model is saved if the model is better\n","    !!!!! for now i saved all the models\n","\n","  :param args: main arguments\n","  :param model: model to train\n","  :param train_state: a dictionary representing the training state values\n","  :returns:\n","      a new train_state\n","  \"\"\"\n","  torch.save(model.state_dict(), train_state['model_filename']+\"_\"+str(train_state['epoch_index'])+\".pth\")\n","  # Save one model at least\n","  if train_state['epoch_index'] == 0:\n","    # torch.save(model.state_dict(), train_state['model_filename'])\n","    train_state['stop_early'] = False\n","\n","  # Save model if performance improved\n","  elif train_state['epoch_index'] >= 1:\n","    loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","    # If loss worsened\n","    if loss_t >= train_state['early_stopping_best_val']:\n","      # Update step\n","      train_state['early_stopping_step'] += 1\n","    # Loss decreased\n","    else:\n","      # Save the best model\n","      # if loss_t < train_state['early_stopping_best_val']:\n","      #     torch.save(model.state_dict(), train_state['model_filename']+\"_\"+str(train_state['epoch_index']+11)+\".pth\")\n","      # Reset early stopping step\n","      train_state['early_stopping_step'] = 0\n","\n","    # Stop early ?\n","    train_state['stop_early'] = \\\n","        train_state['early_stopping_step'] >= args.early_stopping_criteria\n","  return train_state\n","\n","def compute_accuracy(y_pred, y_target):\n","  _, y_pred_indices = y_pred.max(dim=1)\n","  n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n","  return n_correct / len(y_pred_indices) * 100"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ig-lwAAkh0w"},"source":["###Initializations"]},{"cell_type":"code","metadata":{"id":"zhbuS8_ZkiE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617621497763,"user_tz":-180,"elapsed":15704,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}},"outputId":"055584a2-2c61-4ed2-f327-7564ce24b885"},"source":["if args.expand_filepaths_to_save_dir:\n","  args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n","  args.reload_name = os.path.join(args.save_dir, args.reload_name)\n","  print(\"Expanded filepaths: \")\n","  print(\"\\t{}\".format(args.model_state_file))\n","  print(\"\\t{}\".format(args.reload_name))\n","\n","# Set seed for reproducibility\n","set_seed_everywhere(args.seed, args.cuda)\n","\n","# handle dirs\n","# handle_dirs(args.save_dir)\n","\n","dataset = LegalDataset()\n","vectorizer = dataset.get_vectorizer()\n","classifier = LegalClassifier(no_classes=args.no_classes)\n","\n","if args.reload_from_files:\n","    # training from a checkpoint\n","    print(\"Reloading previous model!\")\n","    classifier.load_state_dict(torch.load(args.reload_name, map_location=torch.device(args.device)))\n","else:\n","    print(\"Creating fresh!\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Expanded filepaths: \n","\t/content/drive/MyDrive/thesis/model_chapter\n","\t/content/drive/MyDrive/thesis/model_subject_0.pth\n","loading validation set...\n","loading training set...\n","loading test set...\n","Processing dataset...\n","Loading BERT tokenizer...\n","Done\n","Loading greek-Bert...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f1h5wBjHw_Gs"},"source":["###Training Loop"]},{"cell_type":"code","metadata":{"id":"lMdq50aOw_Mr","colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["8d3724f1a72649f0a5e68e3ce72c11d6","564182f3f8a64bb980d4a29894c67919","757d3b55e0264502ac442384396ec504","bda130700fc541508d8d66ea02378261","65c0975ef84b4d5dabf3f0ef53eac680","ad34a66fce1a48b2ad25ef0f548e44ae","b9112cf636f2475eae5b69b06e0415d9","bf654533b99c4824a00b46b84d02d19a","ec82c45803bc4411b7a5d5d6a31e1bf7","35e78130132648abbc91bf01325d11cd","1bdef2a237d844f8892b748522020c1e","011f129e41604c24b0bd458db2c2d3da","b009ab28de5548d7995595c1192853b7","8261b690d3d74333835acc37e2506137","ddab8d220f3745b2b8a78b480aca9abf","eb98180034f74b2b99492b45a154ea90","49bf86ded83f469ba7d134bb3cbc6d3d","23ddd2eb324d4fcd9180265c474943bb","4d4adaa2594b4c399d0b12240f8a255a","8b21e37f8b9e4deab33b8926e914545c","a963c91ac28e42349d5a2b3ee584eb9a","819d44c07ad2465bb1488b52b0819bf3","4f49feb4353249218929dc3bd5c932e4","60dd146854284acfbaa73780c0a6646d"]},"executionInfo":{"status":"ok","timestamp":1617634604135,"user_tz":-180,"elapsed":13122067,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}},"outputId":"cd9684be-2a4d-4024-ac47-44311d2e480e"},"source":["if args.train:\n","  classifier = classifier.to(args.device)\n","  # dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","  loss_func = nn.CrossEntropyLoss()#weight=dataset.class_weights)\n","  optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n","  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, \n","                                                  mode='min', factor=0.5, patience=1)\n","\n","  train_state = make_train_state(args)\n","\n","  epoch_bar = tqdm(desc='training routine', \n","                            total=args.num_epochs,\n","                            position=0)\n","\n","  dataset.set_split('train')\n","  train_bar = tqdm(desc='split=train',\n","                            total=dataset.get_num_batches(args.batch_size), \n","                            position=1, \n","                            leave=True)\n","  dataset.set_split('val')\n","  val_bar = tqdm(desc='split=val',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","  try:\n","    for epoch_index in range(args.num_epochs):\n","      train_state['epoch_index'] = epoch_index\n","\n","      # Iterate over training dataset\n","\n","      # setup: batch generator, set loss and acc to 0, set train mode on\n","\n","      dataset.set_split('train')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.0\n","      running_acc = 0.0\n","      classifier.train()\n","\n","      for batch_index, batch_dict in enumerate(batch_generator):\n","        # the training routine is these 5 steps:\n","\n","        # --------------------------------------\n","        # step 1. zero the gradients\n","        optimizer.zero_grad()\n","        # step 2. compute the output\n","        y_pred = classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","        # step 3. compute the loss\n","        loss = loss_func(y_pred, batch_dict['target'])\n","        loss_t = loss.item()\n","        running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","        # step 4. use loss to produce gradients\n","        loss.backward()\n","\n","        # step 5. use optimizer to take gradient step\n","        optimizer.step()\n","        # -----------------------------------------\n","        # compute the accuracy\n","        acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","        running_acc += (acc_t - running_acc) / (batch_index + 1)\n","\n","        # update bar\n","        train_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                        epoch=epoch_index)\n","        train_bar.update()\n","\n","      train_state['train_loss'].append(running_loss)\n","      train_state['train_acc'].append(running_acc)\n","\n","      # Iterate over val dataset\n","\n","      # setup: batch generator, set loss and acc to 0; set eval mode on\n","      dataset.set_split('val')\n","      batch_generator = generate_batches(dataset, \n","                                          batch_size=args.batch_size, \n","                                          device=args.device)\n","      running_loss = 0.\n","      running_acc = 0.\n","      classifier.eval()\n","      with torch.no_grad():\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","          # compute the output\n","          y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze())\n","\n","          # compute the loss\n","          loss = loss_func(y_pred, batch_dict['target'])\n","          loss_t = loss.to(\"cpu\").item()\n","          running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","          # compute the accuracy\n","          acc_t = compute_accuracy(y_pred, batch_dict['target'])\n","          running_acc += (acc_t - running_acc) / (batch_index + 1)\n","          val_bar.set_postfix(loss=running_loss, acc=running_acc, \n","                          epoch=epoch_index)\n","          \n","          val_bar.update()\n","\n","      train_state['val_loss'].append(running_loss)\n","      train_state['val_acc'].append(running_acc)\n","\n","      train_state = update_train_state(args=args, model=classifier,\n","                                        train_state=train_state)\n","\n","      scheduler.step(train_state['val_loss'][-1])\n","\n","      if train_state['stop_early']:\n","        break\n","\n","      train_bar.n = 0\n","      val_bar.n = 0\n","      epoch_bar.update()\n","  except KeyboardInterrupt:\n","      print(\"Exiting loop\")"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d3724f1a72649f0a5e68e3ce72c11d6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training routine', max=15.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec82c45803bc4411b7a5d5d6a31e1bf7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train', max=3567.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49bf86ded83f469ba7d134bb3cbc6d3d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=val', max=1188.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Exiting loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GwHo8Wr5aeIc","executionInfo":{"status":"ok","timestamp":1617634604139,"user_tz":-180,"elapsed":13122065,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["# print(train_state['val_acc'])\n","# print(train_state['val_loss'])\n","# print(train_state['train_loss'])\n","# print(train_state['train_acc'])"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOXfsB2Y69Bd"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"2ENl_kjXBEki","executionInfo":{"status":"ok","timestamp":1617634604141,"user_tz":-180,"elapsed":13122065,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["# compute the metrics on the test set using the reload_name model\n","\n","# classifier.load_state_dict(torch.load(args.model_state_file))\n","\n","classifier = classifier.to(args.device)\n","# dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","dataset.set_split('test')\n","batch_generator = generate_batches(dataset, \n","                                   batch_size=args.batch_size, \n","                                   device=args.device)\n","\n","test_bar = tqdm(desc='split=test',\n","                          total=dataset.get_num_batches(args.batch_size), \n","                          position=1, \n","                          leave=True)\n","\n","metric_collection = MetricCollection([\n","    Accuracy(),\n","    Precision(num_classes=args.no_classes, average='micro'),\n","    Recall(num_classes=args.no_classes, average='micro'),\n","    F1(num_classes=args.no_classes, average='micro')\n","]).to(args.device)\n","\n","classifier.eval()\n","with torch.no_grad():\n","  for batch_index, batch_dict in enumerate(batch_generator):\n","    # compute output\n","    y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","    # compute metrics\n","    metric_collection.update(y_pred, batch_dict['target'])\n","    test_bar.update()\n","\n","metrics = metric_collection.compute()\n","print(metrics)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3_HsyZljgX3C"},"source":["save model output and target for all versions (to compute metrics later)\n","this is probably useless, as we only need metrics from the last(best), version. Also it is unusable for everything other than volume, cause the pkl file is too big (>7gb) "]},{"cell_type":"code","metadata":{"id":"DzRDHukTMn8T","colab":{"base_uri":"https://localhost:8080/","height":414,"referenced_widgets":["672ab55a43ce4ee8ae75679d9b1e4d1c","8b278fc896da4ebf8ce819c373efe7a0","1885e859f0b84871919681058a73cf94","54575125420f4798956a4e409180944a","c9a5e2e123304b6f8f37827f235818d3","fb536c6aa4b8498e848c807ad7ab100c","726bfd65dc6b41d2a17afe0933d5594c","e8392b915bf74170a2cb2f6da1317280"]},"executionInfo":{"status":"error","timestamp":1617634624353,"user_tz":-180,"elapsed":13142268,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}},"outputId":"4db571f0-952c-4466-c817-105bfc69d38d"},"source":["# predictions = {}\n","# correct = {}\n","\n","# for i in range(11):\n","#   model_name = args.model_state_file + \"_\" + str(i) + \".pth\"\n","#   classifier.load_state_dict(torch.load(model_name, map_location=torch.device(args.device)))\n","#   # classifier.load_state_dict(torch.load(args.model_state_file))\n","\n","#   classifier = classifier.to(args.device)\n","#   # dataset.class_weights = dataset.class_weights.to(args.device)\n","\n","#   dataset.set_split('test')\n","#   batch_generator = generate_batches(dataset, \n","#                                     batch_size=args.batch_size, \n","#                                     device=args.device)\n","\n","#   test_bar = tqdm(desc='split=test',\n","#                             total=dataset.get_num_batches(args.batch_size), \n","#                             position=1, \n","#                             leave=True)\n","\n","#   metric_collection = MetricCollection([\n","#       Accuracy(),\n","#       Precision(num_classes=args.no_classes, average='micro'),\n","#       Recall(num_classes=args.no_classes, average='micro'),\n","#       F1(num_classes=args.no_classes, average='micro')\n","#   ]).to(args.device)\n","\n","#   predictions[i] = []\n","#   correct[i] = []\n","\n","#   classifier.eval()\n","#   with torch.no_grad():\n","#     for batch_index, batch_dict in enumerate(batch_generator):\n","#       # compute the output\n","#       y_pred =  classifier(batch_dict['vector'].squeeze(), batch_dict['mask'].squeeze(), apply_softmax=True)\n","#       predictions[i] += y_pred\n","#       correct[i] += batch_dict['target']\n","#       # compute the metrics\n","#       metric_collection.update(y_pred, batch_dict['target'])\n","#       test_bar.update()\n","\n","#   metrics = metric_collection.compute()\n","#   print(metrics)\n","\n","# ans = {'predictions' : predictions,\n","#        'correct' : correct}\n","# # save dictionary to pkl\n","# with open(args.save_dir+\"model_predictions/\"+args.class_name+\".pkl\", 'wb') as handle:\n","#     pickle.dump(ans, handle)"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"672ab55a43ce4ee8ae75679d9b1e4d1c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=test', max=1189.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-edbbeacd7c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;31m# compute the metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mmetric_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0mtest_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/collections.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mm_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_computed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         correct, total = _accuracy_update(\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36m_accuracy_update\u001b[0;34m(preds, target, threshold, top_k, subset_accuracy)\u001b[0m\n\u001b[1;32m     24\u001b[0m ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_format_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTILABEL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/checks.py\u001b[0m in \u001b[0;36m_input_format_classification\u001b[0;34m(preds, target, threshold, top_k, num_classes, is_multiclass)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mis_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_multiclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     )\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/checks.py\u001b[0m in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, is_multiclass, top_k)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# Baisc validation (that does not need case/type information)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0m_basic_input_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multiclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# Check that shape/types fall into one of the cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchmetrics/classification/checks.py\u001b[0m in \u001b[0;36m_basic_input_validation\u001b[0;34m(preds, target, threshold, is_multiclass)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be an integer tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be a non-negative tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"3C392X6-hsIG"},"source":["load the pkl dictionary, compute and plot a metric ex persicion"]},{"cell_type":"code","metadata":{"id":"vU4EEY1IGXKT","executionInfo":{"status":"aborted","timestamp":1617634623810,"user_tz":-180,"elapsed":13141720,"user":{"displayName":"John John","photoUrl":"","userId":"16015845607475251502"}}},"source":["# # read dictionary from pkl \n","# handle = open(args.save_dir+\"model_predictions/\"+args.class_name+\".pkl\", 'rb')\n","# predictions = pickle.load(handle)\n","\n","# total_epocs = len(predictions['predictions'])\n","\n","# metric_collection = MetricCollection([\n","#   Accuracy(),\n","#   Precision(num_classes=args.no_classes, average='micro'),\n","#   Recall(num_classes=args.no_classes, average='micro'),\n","#   F1(num_classes=args.no_classes, average='micro')\n","# ]).to(args.device)\n","\n","# bar = tqdm(desc='',total=total_epocs, \n","#                             position=1, \n","#                             leave=True)\n","\n","# # compute percision for each epoch \n","# prec = []\n","# for i in range(total_epocs):\n","#   metric_collection.update(torch.stack(predictions['predictions'][i]), torch.stack(predictions['correct'][i]))\n","#   prec.append(metric_collection.compute()['Precision'].item())\n","#   metric_collection.reset()\n","#   bar.update()\n","\n","# # plot percision\n","# import matplotlib.pyplot as plt\n","# %matplotlib inline\n","# epocs = range(total_epocs)\n","# plt.plot(epocs, prec, color='blue')"],"execution_count":null,"outputs":[]}]}